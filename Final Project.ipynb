{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Custom Entailment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from models.textual_entailment import TextualEntailment\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "\n",
    "class Entailment:\n",
    "    \n",
    "    def __init__(self, load_elmo: bool = True, input_dim: int = 400):\n",
    "        self.input_dim = 400\n",
    "        if load_elmo:\n",
    "            self._frozen = Predictor.from_path(\"./models/textual_entailment.tar.gz\", cuda_device=0)\n",
    "        self._model = self._model()\n",
    "        \n",
    "    def _map(self, label: int) -> str:\n",
    "        \"\"\" Maps the label to the value \"\"\"\n",
    "        switcher = {\n",
    "            0: 'SUPPORTS',\n",
    "            1: 'NOT ENOUGH INFO',\n",
    "            2: 'REFUTES'\n",
    "        }\n",
    "        return switcher[label]\n",
    "\n",
    "    def _model(self) -> nn.Sequential:\n",
    "        \"\"\" Builds the MLP for the classification \"\"\"\n",
    "        model = nn.Sequential(\n",
    "          nn.Linear(400,100),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(100,3),\n",
    "          nn.Softmax(dim=1)\n",
    "        )\n",
    "        model.cuda()\n",
    "        return model\n",
    "    \n",
    "    def save(self, path: str = './models/entailment.model') -> None:\n",
    "        \"\"\" Saves the model to the file \"\"\"\n",
    "        torch.save(self._model.state_dict(), path)\n",
    "        \n",
    "    def load(self, path: str = './models/entailment.model') -> bool:\n",
    "        \"\"\" Loads the model, if possible \"\"\"\n",
    "        if os.path.exists(path):\n",
    "            self._model.load_state_dict(torch.load(path))\n",
    "            return True\n",
    "        raise ValueError(f\"Path {path} is not valid\")\n",
    "\n",
    "    def entail_dataset(self, dataset: Dataset, batch_size: int = 50, \n",
    "                       total_size: int = 30000) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\" Entails all the data and returns the entailed texts \"\"\"\n",
    "        dataset = dataset.shuffle(seed=42)[:total_size]\n",
    "        X = self.entail_batch(dataset['premise'], dataset['hypothesis'], batch_size)\n",
    "        y = torch.tensor(dataset['label'])\n",
    "        return X, y\n",
    "    \n",
    "    def entail_batch(self, premises: List[str], hypotheses: List[str], batch_size: int = 50) -> np.ndarray:\n",
    "        \"\"\" Entails all the data and returns the entailed texts \"\"\"\n",
    "        batches = [dict(premise=v[0], hypothesis=v[1]) for v in zip(premises, hypotheses)]\n",
    "        total_size = len(batches)\n",
    "        \n",
    "        if total_size < batch_size:\n",
    "            batch_size = total_size\n",
    "            \n",
    "        iters = int(total_size / batch_size)\n",
    "        X = list()\n",
    "        \n",
    "        start = 0\n",
    "        for j in tqdm(range(iters)):\n",
    "            end = start + batch_size\n",
    "            batch_json = self._frozen.predict_batch_json(batches[start:end])\n",
    "            X.extend([e['aggregate_input'] for e in batch_json])\n",
    "            start = end\n",
    "        return torch.tensor(X)\n",
    "        \n",
    "    def predict(self, premises: List[str], hypotheses: List[str], batch_size: int = 50) -> torch.Tensor:\n",
    "        \"\"\" Predicts the next word for the text \"\"\"\n",
    "        embedding = self.entail_batch(premises, hypotheses)\n",
    "        embedding = embedding.cuda()\n",
    "        preds = self._model(embedding)\n",
    "        return preds\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray, y: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\" Evaluates the model on the test set \"\"\"\n",
    "        n, _ = X.size()\n",
    "        val = self._model(X)\n",
    "        preds = torch.argmax(val, dim=1)\n",
    "        total = float(sum(preds == y)) / n\n",
    "        return total\n",
    "\n",
    "    def fit(self, X_train: torch.Tensor, y_train: torch.Tensor, X_val: torch.Tensor, y_val: torch.Tensor, \n",
    "            batch_size: int = 32, epochs: int = 100, shuffle: bool = True) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\" Fits the data on the model \"\"\"\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self._model.parameters(), lr=1E-3)\n",
    "        \n",
    "        X_train = X_train.cuda()\n",
    "        y_train = y_train.long().cuda()\n",
    "        X_val = X_val.cuda()\n",
    "        y_val = y_val.long().cuda()\n",
    "        \n",
    "        n, _ = X_train.shape\n",
    "        tr_iters = int(n / batch_size)\n",
    "        \n",
    "        n, _ = X_val.shape\n",
    "        val_iters = int(n / batch_size)\n",
    "        \n",
    "        train_loss = np.zeros(epochs)\n",
    "        train_acc = np.zeros(epochs)\n",
    "        validation_loss = np.zeros(epochs)\n",
    "        validation_acc = np.zeros(epochs)\n",
    "        for epoch in range(epochs):\n",
    "            # Train and Validation Loss\n",
    "            total_loss = self._fit(X_train, y_train, criterion, optimizer, tr_iters, batch_size, shuffle)\n",
    "            val_loss = self._loss(X_val, y_val, criterion, val_iters, batch_size, shuffle)\n",
    "            \n",
    "            total_acc = self.evaluate(X_train, y_train)\n",
    "            val_acc = self.evaluate(X_val, y_val)\n",
    "            \n",
    "            print('[%d] loss: %.7f acc: %.7f \\t val_loss: %.7f val_acc: %.7f' % \n",
    "                  (epoch + 1, total_loss, total_acc, val_loss, val_acc)\n",
    "                 )\n",
    "            \n",
    "            train_loss[epoch] = total_loss\n",
    "            train_acc[epoch] = total_acc\n",
    "            \n",
    "            validation_loss[epoch] = val_loss\n",
    "            validation_acc[epoch] = val_acc\n",
    "        return train_loss, train_acc, validation_loss, validation_acc\n",
    "    \n",
    "    def _fit(self, X: torch.Tensor, y: torch.Tensor, criterion: nn.CrossEntropyLoss, \n",
    "             optimizer: optim.Adam, num_iters: int, batch_size: int = 32, \n",
    "             shuffle: bool = True) -> Tuple[float, float]:\n",
    "        \"\"\" Runs an epoch of training \"\"\"\n",
    "        total_loss = 0.0\n",
    "        if shuffle: \n",
    "            indices = np.random.permutation(range(X.shape[0]))\n",
    "        else:\n",
    "            indices = list(range(X.shape[0]))\n",
    "\n",
    "        start = 0\n",
    "        for i in range(num_iters):\n",
    "            end = start + batch_size\n",
    "            i = indices[start:end]\n",
    "            xi, yi = X[i], y[i]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = self._model(xi)\n",
    "            loss = criterion(outputs, yi)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            start = end\n",
    "\n",
    "        total_loss /= X.shape[0]\n",
    "        return total_loss\n",
    "    \n",
    "    def _loss(self, X: torch.Tensor, y: torch.Tensor, criterion: nn.CrossEntropyLoss, \n",
    "              num_iters: int, batch_size: int = 32, shuffle: bool = True) -> Tuple[float, float]:\n",
    "        \"\"\" Runs an epoch of training \"\"\"\n",
    "        total_loss = 0.0\n",
    "\n",
    "        if shuffle: \n",
    "            indices = np.random.permutation(range(X.shape[0]))\n",
    "        else:\n",
    "            indices = list(range(X.shape[0]))\n",
    "\n",
    "        start = 0\n",
    "        for i in range(num_iters):\n",
    "            end = start + batch_size\n",
    "            i = indices[start:end]\n",
    "            xi, yi = X[i], y[i]\n",
    "\n",
    "            # forward + loss\n",
    "            outputs = self._model(xi)\n",
    "            loss = criterion(outputs, yi)\n",
    "            total_loss += loss.item()\n",
    "            start = end\n",
    "        total_loss /= X.shape[0]\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: Do not run the below code unless you want to regenerate the entailments. **THIS TAKES A LONG TIME TO DO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "snli_data = load_dataset('snli')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "snli_data['train'].shape, snli_data['validation'].shape, snli_data['test'].shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "entailment = Entailment()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def get_balanced_data(entailment: Entailment, data: Dataset) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\" Gets the training data for the entailment model \"\"\"\n",
    "    entailments = data.filter(lambda x: x['label'] == 0)\n",
    "    neutrals = data.filter(lambda x: x['label'] == 1)\n",
    "    contradictions = data.filter(lambda x: x['label'] == 2)\n",
    "    X_entail, y_entail = entailment.entail_dataset(entailments, batch_size=100, total_size=100000)\n",
    "    X_neutral, y_neutral = entailment.entail_dataset(neutrals, batch_size=100, total_size=100000)\n",
    "    X_contra, y_contra = entailment.entail_dataset(contradictions, batch_size=100, total_size=100000)\n",
    "    X_train = torch.vstack((X_entail, X_neutral))\n",
    "    X_train = torch.vstack((X_train, X_contra))\n",
    "    y_train = torch.hstack((y_entail, y_neutral))\n",
    "    y_train = torch.hstack((y_train, y_contra))\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = get_balanced_data(entailment, snli_data['train'])\n",
    "X_train.shape, y_train.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sum(y_train == 0), sum(y_train == 1), sum(y_train == 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x_train_path = './data/x_train.pt'\n",
    "torch.save(X_train, x_train_path)\n",
    "\n",
    "y_train_path = './data/y_train.pt'\n",
    "torch.save(y_train, y_train_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "total_val = snli_data['validation'].shape[0]\n",
    "X_val, y_val = entailment.entail_dataset(snli_data['validation'], batch_size=100, total_size=total_val)\n",
    "X_val.shape, y_val.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x_val_path = './data/x_validation.pt'\n",
    "torch.save(X_val, x_val_path)\n",
    "\n",
    "y_val_path = './data/y_validation.pt'\n",
    "torch.save(y_val, y_val_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "total_test = snli_data['test'].shape[0]\n",
    "X_test, y_test = entailment.entail_dataset(snli_data['test'], batch_size=100, total_size=total_test)\n",
    "X_test.shape, y_test.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x_test_path = './data/x_test.pt'\n",
    "torch.save(X_test, x_test_path)\n",
    "\n",
    "y_test_path = './data/y_test.pt'\n",
    "torch.save(y_test, y_test_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arrays(x_path: str, y_path: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    X = torch.load(x_path)\n",
    "    y = torch.load(y_path)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300000, 400]), torch.Size([300000]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_path = './data/x_train.pt'\n",
    "y_train_path = './data/y_train.pt'\n",
    "\n",
    "X_train, y_train = load_arrays(x_train_path, y_train_path)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(100000), tensor(100000), tensor(100000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train == 0), sum(y_train == 1), sum(y_train == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9842, 400]), torch.Size([9842]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_path = './data/x_validation.pt'\n",
    "y_val_path = './data/y_validation.pt'\n",
    "\n",
    "X_val, y_val = load_arrays(x_val_path, y_val_path)\n",
    "\n",
    "pos = torch.nonzero(y_val != -1)  # Remove -1\n",
    "pos = pos.reshape(pos.size()[0])  # Remove -1\n",
    "\n",
    "X_val = X_val[pos]\n",
    "y_val = y_val[pos]\n",
    "\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3329), tensor(3235))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_val == 0), sum(y_val == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9824, 400]), torch.Size([9824]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_path = './data/x_test.pt'\n",
    "y_test_path = './data/y_test.pt'\n",
    "\n",
    "X_test, y_test = load_arrays(x_test_path, y_test_path)\n",
    "\n",
    "pos = torch.nonzero(y_test != -1)  # Remove -1\n",
    "pos = pos.reshape(pos.size()[0])  # Remove -1\n",
    "\n",
    "X_test = X_test[pos]\n",
    "y_test = y_test[pos]\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3368), tensor(3219))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test == 0), sum(y_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailment = Entailment(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.0205580 acc: 0.8926800 \t val_loss: 0.0215004 val_acc: 0.8585653\n",
      "[2] loss: 0.0203489 acc: 0.9008433 \t val_loss: 0.0213094 val_acc: 0.8663889\n",
      "[3] loss: 0.0202893 acc: 0.9038533 \t val_loss: 0.0212813 val_acc: 0.8653729\n",
      "[4] loss: 0.0202557 acc: 0.9017500 \t val_loss: 0.0213416 val_acc: 0.8642552\n",
      "[5] loss: 0.0202150 acc: 0.9056867 \t val_loss: 0.0212463 val_acc: 0.8672018\n",
      "[6] loss: 0.0201876 acc: 0.9050367 \t val_loss: 0.0213716 val_acc: 0.8627312\n",
      "[7] loss: 0.0201700 acc: 0.9064367 \t val_loss: 0.0212367 val_acc: 0.8686243\n",
      "[8] loss: 0.0201386 acc: 0.9074167 \t val_loss: 0.0212640 val_acc: 0.8672018\n",
      "[9] loss: 0.0201345 acc: 0.9068500 \t val_loss: 0.0212183 val_acc: 0.8687259\n",
      "[10] loss: 0.0201165 acc: 0.9089167 \t val_loss: 0.0213008 val_acc: 0.8651697\n"
     ]
    }
   ],
   "source": [
    "loss, acc, val_loss, val_acc = entailment.fit(X_train, y_train, X_val, y_val, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = list(range(10))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560667752442996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment.evaluate(X_test.cuda(), y_test.long().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560667752442996"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Entailment(False)\n",
    "model.load()\n",
    "model.evaluate(X_test.cuda(), y_test.long().cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Facebook Experiment\n",
    "\n",
    "1. Implement automatic masking\n",
    "2. Get the top 1 prediction from the LM \n",
    "3. Fill in the mask\n",
    "4. Use the claim and filled in sentence and input into an entailment model\n",
    "5. Input entailment into MLP for final fact-verification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Iterable, List, Tuple\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from models.textual_entailment import TextualEntailment\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    def __init__(self, tokenizer, unmasker, model):\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.mask_token = tokenizer.mask_token\n",
    "        self.tokenizer = tokenizer\n",
    "        self.unmasker = unmasker.to(self.device)\n",
    "        self.model = model\n",
    "        self.vocab = tokenizer.get_vocab()\n",
    "        \n",
    "    def __call__(self, dataset: Dataset = None, limit: int = 0, save: bool = False, load: bool = False,\n",
    "                 path: str = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\" Performs all operations on the dataset \"\"\"\n",
    "        if (save or load) and not path:\n",
    "            raise ValueError(\"Must pass a path to save the processed dataset\")\n",
    "        \n",
    "        if load and os.path.exists(path):\n",
    "            dataset = load_dataset('csv', data_files=[path])['train']\n",
    "            return self.evaluate_dataset(dataset)\n",
    "        \n",
    "        print(\"Masking the claims and filling the masks for the dataset\")\n",
    "        data = self.mask_and_fill(dataset, limit)\n",
    "        if save:\n",
    "            print(\"Saving checkpoint...\")\n",
    "            data.to_csv(path)\n",
    "        return self.evaluate_dataset(data)\n",
    "        \n",
    "    def mask_and_fill(self, dataset: Dataset, limit: int = 0) -> Dataset:\n",
    "        \"\"\" Masks the entire dataset \"\"\"            \n",
    "        if limit != 0:\n",
    "            dataset = dataset.select(list(range(limit)))\n",
    "        data = dataset.map(self._mask)\n",
    "        data = data.filter(lambda x: x['masked'] is not None)\n",
    "        data = data.map(self._fill)\n",
    "        return data\n",
    "    \n",
    "    def _mask(self, x: dict) -> dict:\n",
    "        \"\"\" Masks the last named entity in the string \"\"\"\n",
    "        x['target'] = None\n",
    "        x['masked'] = None\n",
    "        x['label'] = self._map(x['label'])\n",
    "        claim = x['claim']\n",
    "        doc = self.nlp(claim, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "        ents = doc.ents\n",
    "        if ents:\n",
    "            target = self._get_target(ents)\n",
    "            if target:  # If the target is not in the vocab, skip the entry\n",
    "                masked = self.mask_token.join(claim.rsplit(target, 1))\n",
    "                x['target'] = target\n",
    "                x['masked'] = masked\n",
    "        return x\n",
    "    \n",
    "    def _get_target(self, ents) -> Optional[str]:\n",
    "        \"\"\" Gets the ideal target \"\"\"\n",
    "        for i in reversed(range(len(ents))):\n",
    "            words = ents[i].text.split()\n",
    "            for word in words:\n",
    "                if self.vocab.get(word):\n",
    "                    return word\n",
    "        return None\n",
    "            \n",
    "    def _fill(self, x: dict) -> dict:\n",
    "        \"\"\" Fills the masked token with the  top-1 predicted value \"\"\"\n",
    "        x['pred'] = self._predict(x['masked'])\n",
    "        x['hypothesis'] = x['masked'].replace(self.mask_token, x['pred'])\n",
    "        return x\n",
    "    \n",
    "    def _predict(self, masked_claim: str) -> str:\n",
    "        \"\"\" Fills the masked token with the  top-1 predicted value \"\"\"\n",
    "        tokens = self.tokenizer(masked_claim, return_tensors='pt')\n",
    "        masked_index = torch.nonzero(tokens['input_ids'][0] == self.tokenizer.mask_token_id, as_tuple=False)\n",
    "        # Fill mask pipeline supports only one ${mask_token} per sample\n",
    "        num = np.prod(masked_index.shape)\n",
    "        if num > 1 or num < 1:\n",
    "            print(masked_claim, tokens, masked_index)\n",
    "            raise ValueError(f\"Pipeline only supports one masked index: {num} is not supported\")\n",
    "\n",
    "        outputs = self.unmasker(**tokens.to(self.device))\n",
    "        logits = outputs.logits[0, masked_index.item(), :]\n",
    "        probs = logits.softmax(dim=0)\n",
    "        values, predictions = probs.topk(1)\n",
    "        word = self.tokenizer.decode(predictions)\n",
    "        return word.strip()\n",
    "    \n",
    "    def predict_batch(self, premises: List[str], hypotheses: List[str], batch_size: int = 50) -> np.ndarray:\n",
    "        \"\"\" Entails all the data and returns the entailed texts \"\"\"\n",
    "        batches = [dict(premise=v[0], hypothesis=v[1]) for v in zip(premises, hypotheses)]\n",
    "        total_size = len(batches)\n",
    "        \n",
    "        if total_size < batch_size:\n",
    "            batch_size = total_size\n",
    "            iters = 1\n",
    "        else:\n",
    "            iters = int(total_size / batch_size) + 1\n",
    "            \n",
    "        X = list()\n",
    "        \n",
    "        start = 0\n",
    "        for j in tqdm(range(iters)):\n",
    "            end = start + batch_size\n",
    "            if end >= total_size:\n",
    "                end = total_size\n",
    "            batch_json = self.model.predict_batch_json(batches[start:end])\n",
    "            X.extend([e['label_probs'] for e in batch_json])\n",
    "            start = end\n",
    "        return torch.tensor(X)\n",
    "    \n",
    "    def evaluate_dataset(self, dataset: Dataset) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\" Evaluates how well the model is able to predict \"\"\"\n",
    "        support = dataset.filter(lambda x: x['target'] == x['pred'])\n",
    "        entail = dataset.filter(lambda x: x['target'] != x['pred'])\n",
    "        assert support.shape[0] + entail.shape[0] == dataset.shape[0]\n",
    "        premise, hypothesis = entail['claim'], entail['hypothesis']\n",
    "        preds = torch.argmax(self.predict_batch(premise, hypothesis), dim=1)\n",
    "        \n",
    "        y_true = support['label']\n",
    "        y_true.extend(entail['label'])\n",
    "        y_pred = np.zeros(support.shape[0])\n",
    "        y_pred = np.concatenate((y_pred, preds), axis=None)\n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def evaluate(self, y_true: List[int], y_pred: List[int]) -> tuple:\n",
    "        \"\"\" Evaluates how well the model is able to predict \"\"\"\n",
    "        metrics = precision_recall_fscore_support(y_true, y_pred)\n",
    "        macro = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        return metrics, macro, acc\n",
    "    \n",
    "    def _map(self, label: int) -> str:\n",
    "        \"\"\" Maps the label to the value \"\"\"\n",
    "        switcher = {\n",
    "            'SUPPORTS': 0,\n",
    "            'NOT ENOUGH INFO': 1,\n",
    "            'REFUTES': 2\n",
    "        }\n",
    "        return switcher[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmack/anaconda3/envs/final-project/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "entailment_model = Predictor.from_path(\"./models/decomposable-attention-elmo-2020.04.09.tar.gz\", cuda_device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fever (/home/jmack/.cache/huggingface/datasets/fever/v1.0/1.0.0/fe391c4f48669454ae0d368997430e6fa476aacb476d930d3328b67356e74625)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18567, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('fever', 'v1.0')\n",
    "data = dataset['paper_test']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertForMaskedLM\n",
    "\n",
    "bert_tokenizer = BertTokenizerFast.from_pretrained('bert-large-cased-whole-word-masking')\n",
    "bert_model = BertForMaskedLM.from_pretrained('bert-large-cased-whole-word-masking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(bert_tokenizer, bert_model, entailment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: Only needs to be run once, otherwise you can load the data directly using the second command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking the claims and filling the masks for the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70915adba30e424d89e9b1f50fa99f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8fb73e0aa2463a80e5c5ceae66d26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427f11685bd1409fa9ce667bcf3daa41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoint...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65336fd4455e428b857eb7fb1c426a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a0056c37ca43a5851e3b1ca61b2f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/174 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 174/174 [00:44<00:00,  3.88it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_y_true, bert_y_pred = pipe(data, save=True, path='./data/bert_paper_test.csv') # Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_y_true, bert_y_pred = pipe(data, load=True, path='./data/bert_paper_test.csv') # Load & Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.40300727, 0.2565445 , 0.475382  ]),\n",
       "  array([0.88546016, 0.11441915, 0.05297011]),\n",
       "  array([0.55390904, 0.15825595, 0.09531915]),\n",
       "  array([5509, 3426, 5286])),\n",
       " (0.3783112587790822, 0.35094980450869645, 0.26916138272532764, None),\n",
       " 0.3902679136488292)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_metrics, bert_macro, bert_acc = pipe.evaluate(bert_y_true, bert_y_pred)\n",
    "bert_metrics, bert_macro, bert_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broad Check on Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART\n",
    "\n",
    "- Unknown training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "bart_tokenizer = BartTokenizerFast.from_pretrained(\"facebook/bart-large\")\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(bart_tokenizer, bart_model, entailment_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking the claims and filling the masks for the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0922939a6b7a4c7183ffade7f4c53caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b13b8ac6afe47f2818e994e31fb1867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3682fe02dcf64fdcb549b9e4216b816f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoint...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c31605c11a44ffd991b7a4f65402b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554c90cade5447839783542583e2b09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/165 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 165/165 [00:42<00:00,  3.88it/s]\n"
     ]
    }
   ],
   "source": [
    "bart_y_true, bart_y_pred = pipe(data, save=True, path='./data/bart_paper_test.csv') # Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d0dc0df88bb2c1a2\n",
      "Reusing dataset csv (/home/jmack/.cache/huggingface/datasets/csv/default-d0dc0df88bb2c1a2/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7309, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_y_true, bart_y_pred = pipe(data, load=True, path='./data/bart_paper_test.csv') # Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.39173097, 0.1962111 , 0.42461538]),\n",
       "  array([0.93115942, 0.05171184, 0.03178991]),\n",
       "  array([0.55146516, 0.08185154, 0.05915131]),\n",
       "  array([4416, 2804, 4341])),\n",
       " (0.33751915048157044, 0.33822039022568334, 0.23082267006517176, None),\n",
       " 0.38015742582821554)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_metrics, bart_macro, bart_acc = pipe.evaluate(bart_y_true, bart_y_pred)\n",
    "bart_metrics, bart_macro, bart_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa\n",
    "\n",
    "- Trained on Bookcorpus, Wikipedia and CC News datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BigBirdForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BigBirdTokenizer, BigBirdForMaskedLM\n",
    "  \n",
    "bigbird_tokenizer = BigBirdTokenizer.from_pretrained(\"google/bigbird-roberta-large\")\n",
    "bigbird_model = BigBirdForMaskedLM.from_pretrained(\"google/bigbird-roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(bigbird_tokenizer, bigbird_model, entailment_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking the claims and filling the masks for the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32ef32fb9fb42a4945fa65ba2c088c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d79c1599b8849a0813466e37671ca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff156b85df54c10b6db04423f52252e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 14 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3.Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoint...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b542a155ccf04754848b64b4b806220c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8ffad097b546c4a80b6b594a3e8d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/212 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 212/212 [00:54<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "bigbird_y_true, bigbird_y_pred = pipe(data, save=True, path='./data/bigbird_paper_test.csv') # Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbird_y_true, bigbird_y_pred = pipe(data, load=True, path='./data/bigbird_paper_test.csv') # Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.39132206, 0.20647773, 0.39072848]),\n",
       "  array([0.87001812, 0.07275321, 0.06795669]),\n",
       "  array([0.5398342 , 0.10759494, 0.11577708]),\n",
       "  array([4416, 2804, 4341])),\n",
       " (0.32950942371145736, 0.33690933921630234, 0.2544020721916476, None),\n",
       " 0.3754865496064354)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_metrics, bb_macro, bb_acc = pipe.evaluate(bigbird_y_true, bigbird_y_pred)\n",
    "bb_metrics, bb_macro, bb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALBERT v2\n",
    "\n",
    "- Model was trained on Bookcorpus and Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizerFast, AlbertForMaskedLM\n",
    "  \n",
    "albert_tokenizer = AlbertTokenizerFast.from_pretrained(\"albert-large-v2\")\n",
    "albert_model = AlbertForMaskedLM.from_pretrained(\"albert-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking the claims and filling the masks for the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36bca696d824480b819c797d58f0359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2967952deb9f456988e0f74393be00a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9f592e2d8a4f8782a286e540971ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5092.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoint...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b1811654454f38b804b00080f17bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b17fbdab764064b0b4cc763192a420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:18<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(albert_tokenizer, albert_model, entailment_model)\n",
    "albert_y_true, albert_y_pred = pipe(data, save=True, path='./data/albert_paper_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e567ee26bac4c5b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/jmack/.cache/huggingface/datasets/csv/default-e567ee26bac4c5b8/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/jmack/.cache/huggingface/datasets/csv/default-e567ee26bac4c5b8/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a729781524948d79e0fd83fb071a8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43632222066843ee966d11f2ee7c1497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  6.59it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = pipe(data, load=True, path='./data/albert_paper_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.35865076, 0.19290466, 0.51590106]),\n",
       "  array([0.89263278, 0.07004831, 0.06955693]),\n",
       "  array([0.51170404, 0.10277614, 0.12258606]),\n",
       "  array([1751, 1242, 2099])),\n",
       " (0.3558188245393494, 0.34407934077297037, 0.24568874746081326, None),\n",
       " 0.3527101335428123)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_metrics, albert_macro, albert_acc = pipe.evaluate(albert_y_true, albert_y_pred)\n",
    "albert_metrics, albert_macro, albert_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- Reporting the precision, recall, F1 score and accuracy from all the above models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(options, name, results):\n",
    "    columns = [name, \"SUPPORTS\", \"NOT ENOUGH INFO\", \"REFUTES\", \"Macro\"]\n",
    "    max_len = len(max(columns, key=lambda x: len(x)))\n",
    "    header = \" | \".join('{0:{width}}'.format(col, width=max_len) for col in columns)\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for i, r in enumerate(results):\n",
    "        r = np.round_(np.multiply(100, r), decimals=2)\n",
    "        line = [options[i], r[0], r[1], r[2], np.average(r)]\n",
    "        print(\" | \".join('{0:{width}}'.format(str(r), width=max_len) for r in line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting a Context Layer into the Pipeline\n",
    "\n",
    "- We will try using the autoregressive language model GPT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning GPT2 on CC News Dataset\n",
    "\n",
    "1. Open up a terminal, navigate to `/path/to/project/finetuning/` and run `run_clm.sh`\n",
    "2. Wait until it finishes\n",
    "3. **Note**: This only trains GPT2 on 150,000 samples of the CC News dataset. Please adjust the script to suit both your GPU settings and your fine-tuning needs\n",
    "4. I plan to upload the model fine-tuned on the complete dataset at a later date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning BART on FEVER\n",
    "\n",
    "1. Open up a terminal, navigate to `/path/to/project/finetuning/` and run `run_mlm.sh`\n",
    "2. Wait until it finishes\n",
    "3. **Note**: This only trains BART on 150,000 samples of the FEVER dataset. Please adjust the script to suit both your GPU settings and your fine-tuning needs\n",
    "4. I plan to upload the model fine-tuned on the complete dataset at a later date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the Pipeline - Adding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Iterable, List, Tuple\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from models.textual_entailment import TextualEntailment\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "from transformers.generation_utils import logger\n",
    "import logging\n",
    "\n",
    "\n",
    "class PipelineWithContext(Pipeline):\n",
    "    \n",
    "    def __init__(self, tokenizer, unmasker, text_generator, model):\n",
    "        super().__init__(tokenizer, unmasker, model)\n",
    "        self.text_generator = text_generator\n",
    "        self.max_len = tokenizer.model_max_length\n",
    "        logger.setLevel(logging.ERROR)\n",
    "    \n",
    "    def __call__(self, dataset: Dataset = None, limit: int = 0, mask: bool = False, context: bool = False,\n",
    "                 fill: bool = False, save: bool = False, load: bool = False, \n",
    "                 path: str = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\" Performs all operations on the dataset \"\"\"\n",
    "        if (save or load) and not path:\n",
    "            raise ValueError(\"Must pass a path to save the processed dataset\")\n",
    "        \n",
    "        if load and os.path.exists(path):\n",
    "            dataset = load_dataset('csv', data_files=[path])['train']\n",
    "        \n",
    "        if dataset and not load:\n",
    "            context = True\n",
    "            fill = True\n",
    "        \n",
    "        if limit != 0:\n",
    "            dataset = dataset.select(list(range(limit)))\n",
    "        \n",
    "        if mask:\n",
    "            print(\"Masking the claims...\")\n",
    "            dataset = dataset.map(self._mask)\n",
    "            dataset = dataset.filter(lambda x: x['target'] != None)\n",
    "        \n",
    "        if context:\n",
    "            print(\"Adding context to the dataset\")\n",
    "            dataset = self.add_context(dataset)\n",
    "            if save:\n",
    "                print(\"Saving checkpoint...\")\n",
    "                dataset.to_csv(path)\n",
    "        if fill:\n",
    "            print(\"Filling the context masks\")\n",
    "            dataset = self.fill_context(dataset)\n",
    "            if save:\n",
    "                print(\"Saving checkpoint...\")\n",
    "                dataset.to_csv(path)\n",
    "        return self.evaluate_dataset(dataset)\n",
    "        \n",
    "    def add_context(self, dataset: Dataset, limit: int = 0) -> Dataset:\n",
    "        \"\"\" Masks the entire dataset \"\"\"            \n",
    "        if limit != 0:\n",
    "            dataset = dataset.select(list(range(limit)))\n",
    "        data = dataset.map(self._contextualize)\n",
    "        return data\n",
    "    \n",
    "    def fill_context(self, dataset: Dataset, limit: int = 0) -> Dataset:\n",
    "        \"\"\" Fills the context map \"\"\"\n",
    "        if limit != 0:\n",
    "            dataset = dataset.select(list(range(limit)))\n",
    "        data = dataset.map(self._fill)\n",
    "        return data\n",
    "    \n",
    "    def _fill(self, x: dict) -> dict:\n",
    "        \"\"\" Masks the claim and fills the mask \"\"\"\n",
    "        x['masked_context'] = x['masked'].join(x['context'].split(x['claim'], 1))\n",
    "        x['context_pred'] = self._predict(x['masked_context'])\n",
    "        x['context_hypothesis'] = x['masked_context'].replace(self.mask_token, x['context_pred'])\n",
    "        x['filled'] = x['masked'].replace(self.mask_token, x['context_pred'])\n",
    "        return x\n",
    "   \n",
    "    def _contextualize(self, x: dict) -> str:\n",
    "        \"\"\" Generates context for the claim \"\"\"\n",
    "        context = self.text_generator(x['claim'], max_length=50, do_sample=False)[0]['generated_text']\n",
    "        if len(context) > self.max_len:\n",
    "            context = context[:self.max_len]\n",
    "        x['context'] = context.replace('\\n', ' ')  # Remove newlines to avoid error in Entailment model\n",
    "        return x\n",
    "    \n",
    "    def evaluate_dataset(self, dataset: Dataset) -> Tuple[float, float, float, float]:\n",
    "        \"\"\" Evaluates how well the model is able to predict \"\"\"\n",
    "        support = dataset.filter(lambda x: x['target'] == x['context_pred'])\n",
    "        entail = dataset.filter(lambda x: x['target'] != x['context_pred'])\n",
    "        assert support.shape[0] + entail.shape[0] == dataset.shape[0]\n",
    "        premise, hypothesis = entail['context'], entail['context_hypothesis']\n",
    "        preds = torch.argmax(self.predict_batch(premise, hypothesis), dim=1)\n",
    "        \n",
    "        y_true = support['label']\n",
    "        y_true.extend(entail['label'])\n",
    "        y_pred = np.zeros(support.shape[0])\n",
    "        y_pred = np.concatenate((y_pred, preds), axis=None)\n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def _map(self, label: int) -> str:\n",
    "        \"\"\" Maps the label to the value \"\"\"\n",
    "        switcher = {\n",
    "            'SUPPORTS': 0,\n",
    "            'NOT ENOUGH INFO': 1,\n",
    "            'REFUTES': 2\n",
    "        }\n",
    "        return switcher[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import pipeline\n",
    "\n",
    "gpt2_dir = '/run/media/jmack/ColdStorage/models/gpt2'\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(gpt2_dir)\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_dir)\n",
    "\n",
    "text_generator = pipeline(\"text-generation\", model=gpt2_model, tokenizer=gpt2_tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "bart_dir = '/run/media/jmack/ColdStorage/models/bart_large'\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(bart_dir)\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(bart_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Toy Example with Finetuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Thomas Jefferson founded the University of Virginia. He was born in Richmond, Virginia, on July 4, 1847. He graduated from the University of Virginia in 1871. He was a member of the Virginia Board of Trustees from 1871 to 1873. He was a member of the Virginia State Board of Education from 1873 to 1874. He was a member of'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Thomas Jefferson founded the University of Virginia.\"\n",
    "masked_text = \"Thomas Jefferson founded the University of <mask>.\"\n",
    "context = text_generator(\"Thomas Jefferson founded the University of Virginia.\", max_length=75, do_sample=False)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thomas Jefferson founded the University of <mask>. He was born in Richmond, Virginia, on July 4, 1847. He graduated from the University of Virginia in 1871. He was a member of the Virginia Board of Trustees from 1871 to 1873. He was a member of the Virginia State Board of Education from 1873 to 1874.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = f\"{'.'.join(context[0]['generated_text'].split('.')[:-1])}.\"\n",
    "masked_context = context.replace(text, masked_text)\n",
    "masked_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Virginia'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(tokenizer, model, masked_claim: str) -> str:\n",
    "    \"\"\" Fills the masked token with the  top-1 predicted value \"\"\"\n",
    "    tokens = tokenizer(masked_claim, return_tensors='pt')\n",
    "    masked_index = torch.nonzero(tokens['input_ids'][0] == tokenizer.mask_token_id, as_tuple=False)\n",
    "    # Fill mask pipeline supports only one ${mask_token} per sample\n",
    "    num = np.prod(masked_index.shape)\n",
    "    if num > 1 or num < 1:\n",
    "        print(masked_claim, tokens, masked_index)\n",
    "        raise ValueError(f\"Pipeline only supports one masked index: {num} is not supported\")\n",
    "\n",
    "    outputs = model(**tokens)\n",
    "    logits = outputs.logits[0, masked_index.item(), :]\n",
    "    probs = logits.softmax(dim=0)\n",
    "    values, predictions = probs.topk(1)\n",
    "    word = tokenizer.decode(predictions)\n",
    "    return word.strip()\n",
    "\n",
    "predict(bart_tokenizer, bart_model, masked_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PipelineWithContext(bart_tokenizer, bart_model, text_generator, entailment_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking the claims and filling the masks for the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805701de1c8642c1888ceac39b545d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed52d79d11fc4e4c97a197e7cf31a47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding context to the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1060f6e47179462ca26402d78176a501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=61.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoint...\n",
      "Filling the context masks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8e280c562d4b6e9e9bb080e5758ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=61.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoint...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fceb03e293cb40ae818acc60c5ba9821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848a2a5407a14117b7b2778362b2b382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "bart_y_true, bart_y_pred = pipe(data, limit=100, mask=True, save=True, path='./data/bart_context_paper_test.csv') # Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'claim', 'evidence_annotation_id', 'evidence_id', 'evidence_sentence_id', 'evidence_wiki_url', 'hypothesis', 'id', 'label', 'masked', 'pred', 'target'],\n",
       "    num_rows: 7309\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_y_true, bart_y_pred = pipe(data, load=True, path='./data/bart_context_paper_test.csv') # Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.21428571, 0.        , 0.46666667]),\n",
       "  array([0.5       , 0.        , 0.24137931]),\n",
       "  array([0.3       , 0.        , 0.31818182]),\n",
       "  array([18, 14, 29])),\n",
       " (0.22698412698412698, 0.2471264367816092, 0.20606060606060606, None),\n",
       " 0.26229508196721313)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_metrics, bart_macro, bart_acc = pipe.evaluate(bart_y_true, bart_y_pred)\n",
    "bart_metrics, bart_macro, bart_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-47e949f1b82769aa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/jmack/.cache/huggingface/datasets/csv/default-47e949f1b82769aa/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/jmack/.cache/huggingface/datasets/csv/default-47e949f1b82769aa/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'claim', 'context', 'context_hypothesis', 'context_pred', 'evidence_annotation_id', 'evidence_id', 'evidence_sentence_id', 'evidence_wiki_url', 'filled', 'id', 'label', 'masked', 'masked_context', 'target'],\n",
       "    num_rows: 61\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = load_dataset('csv', data_files=['./data/bart_context_paper_test.csv'])['train']\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ukrainian Soviet Socialist Republic was a founding participant of the Olympics. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding',\n",
       "  'Ukrainian Soviet Socialist Republic was a founding participant of the <mask>. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding'),\n",
       " ('Ukrainian Soviet Socialist Republic was a founding participant of the Olympics. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding',\n",
       "  'Ukrainian Soviet Socialist Republic was a founding participant of the <mask>. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding'),\n",
       " ('Ukrainian Soviet Socialist Republic was a founding participant of the Olympics. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding',\n",
       "  'Ukrainian Soviet Socialist Republic was a founding participant of the <mask>. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding'),\n",
       " ('Ukrainian Soviet Socialist Republic was a founding participant of the Olympics. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding',\n",
       "  'Ukrainian Soviet Socialist Republic was a founding participant of the <mask>. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding'),\n",
       " ('Ukrainian Soviet Socialist Republic was a founding participant of the Olympics. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding',\n",
       "  'Ukrainian Soviet Socialist Republic was a founding participant of the <mask>. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding'),\n",
       " ('Ukrainian Soviet Socialist Republic was a founding participant of the Olympics. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding',\n",
       "  'Ukrainian Soviet Socialist Republic was a founding participant of the <mask>. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding'),\n",
       " ('Ukrainian Soviet Socialist Republic was a founding participant of the Olympics. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding',\n",
       "  'Ukrainian Soviet Socialist Republic was a founding participant of the <mask>. The UN has been a major source of funding for the UN and has been instrumental in the creation of the UN Security Council. The UN has been a major source of funding'),\n",
       " ('The New Jersey Turnpike has no shoulders. The state has a long history of bike-sharing, with the states first bike-sharing station in the 1930s. The states first bike-sharing station was',\n",
       "  'The New Jersey Turnpike has <mask> shoulders. The state has a long history of bike-sharing, with the states first bike-sharing station in the 1930s. The states first bike-sharing station was'),\n",
       " ('Entertainment Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries',\n",
       "  '<mask> Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries'),\n",
       " ('Entertainment Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries',\n",
       "  '<mask> Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries'),\n",
       " ('Entertainment Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries',\n",
       "  '<mask> Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries'),\n",
       " ('Entertainment Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries',\n",
       "  '<mask> Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries'),\n",
       " ('Entertainment Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries',\n",
       "  '<mask> Entertainment is the owner of Wanda Cinemas. The company is a subsidiary of the company that owns the Wanda Cinema in New York City. Wanda is a global entertainment company that operates in the entertainment, entertainment, and entertainment industries'),\n",
       " ('Aruba is the only Paradise Island. The show is based on the real-life story of a young woman who is kidnapped by a group of kidnappers. The show is produced by ABC Studios and is produced by Warner Bros. Television.',\n",
       "  'Aruba is the only <mask> Island. The show is based on the real-life story of a young woman who is kidnapped by a group of kidnappers. The show is produced by ABC Studios and is produced by Warner Bros. Television.'),\n",
       " ('Aruba is the only Paradise Island. The show is based on the real-life story of a young woman who is kidnapped by a group of kidnappers. The show is produced by ABC Studios and is produced by Warner Bros. Television.',\n",
       "  'Aruba is the only <mask> Island. The show is based on the real-life story of a young woman who is kidnapped by a group of kidnappers. The show is produced by ABC Studios and is produced by Warner Bros. Television.'),\n",
       " ('Burbank, California has always been completely void of industry. The company has been a pioneer in the field of automotive safety, but it has also been a pioneer in the field of safety education. The company has been a pioneer in the field',\n",
       "  'Burbank, <mask> has always been completely void of industry. The company has been a pioneer in the field of automotive safety, but it has also been a pioneer in the field of safety education. The company has been a pioneer in the field'),\n",
       " (\"The Guthrie Theater's second building began operating in 2009. The Guthrie Theater is located at the corner of North and North Avenue in the downtown area of the city. The Guthrie Theater is open to the public from 9 a.m\",\n",
       "  \"The Guthrie Theater's second building began operating in <mask>. The Guthrie Theater is located at the corner of North and North Avenue in the downtown area of the city. The Guthrie Theater is open to the public from 9 a.m\"),\n",
       " ('Hezbollah received a type of training from the. The Iranian Revolutionary Guard Corps (IRGC) is a paramilitary force that is responsible for the security of the Iranian-backed Hezbollah movement. The IRGC is a paramilitary force that is responsible for',\n",
       "  'Hezbollah received a type of training from <mask>. The Iranian Revolutionary Guard Corps (IRGC) is a paramilitary force that is responsible for the security of the Iranian-backed Hezbollah movement. The IRGC is a paramilitary force that is responsible for'),\n",
       " ('Hezbollah received a type of training from the. The Iranian Revolutionary Guard Corps (IRGC) is a paramilitary force that is responsible for the security of the Iranian-backed Hezbollah movement. The IRGC is a paramilitary force that is responsible for',\n",
       "  'Hezbollah received a type of training from <mask>. The Iranian Revolutionary Guard Corps (IRGC) is a paramilitary force that is responsible for the security of the Iranian-backed Hezbollah movement. The IRGC is a paramilitary force that is responsible for'),\n",
       " ('Practical Magic is an American romantic drama film. The film is based on the true story of a young woman who is forced to marry a man who is a serial killer. The film stars Jennifer Lawrence, Reese Witherspoon, and',\n",
       "  'Practical Magic is an <mask> romantic drama film. The film is based on the true story of a young woman who is forced to marry a man who is a serial killer. The film stars Jennifer Lawrence, Reese Witherspoon, and'),\n",
       " ('Corsica belongs to United. The club has been linked with a move for the midfielder, who has been linked with a move to Manchester United. The 25-year-old has been linked with a move to Manchester United, with reports',\n",
       "  'Corsica belongs to <mask>. The club has been linked with a move for the midfielder, who has been linked with a move to Manchester United. The 25-year-old has been linked with a move to Manchester United, with reports'),\n",
       " ('Corsica belongs to United. The club has been linked with a move for the midfielder, who has been linked with a move to Manchester United. The 25-year-old has been linked with a move to Manchester United, with reports',\n",
       "  'Corsica belongs to <mask>. The club has been linked with a move for the midfielder, who has been linked with a move to Manchester United. The 25-year-old has been linked with a move to Manchester United, with reports'),\n",
       " (\"The Bourne removed Riz Ahmed from the movie's cast. The actor, who plays the role of a young man who is a member of the gang, was seen in the trailer for the film. The actor, who plays the role\",\n",
       "  \"<mask> Bourne removed Riz Ahmed from the movie's cast. The actor, who plays the role of a young man who is a member of the gang, was seen in the trailer for the film. The actor, who plays the role\"),\n",
       " ('Dennis Dennis is unemployed. Im not going to be able to work, he said. Im not going to be able to do anything. Dennis said hes',\n",
       "  '<mask> Dennis is unemployed. Im not going to be able to work, he said. Im not going to be able to do anything. Dennis said hes'),\n",
       " ('Dennis Dennis is unemployed. Im not going to be able to work, he said. Im not going to be able to do anything. Dennis said hes',\n",
       "  '<mask> Dennis is unemployed. Im not going to be able to work, he said. Im not going to be able to do anything. Dennis said hes'),\n",
       " ('Dennis Dennis is unemployed. Im not going to be able to work, he said. Im not going to be able to do anything. Dennis said hes',\n",
       "  '<mask> Dennis is unemployed. Im not going to be able to work, he said. Im not going to be able to do anything. Dennis said hes'),\n",
       " ('Just Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. ',\n",
       "  '<mask> Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. '),\n",
       " ('Just Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. ',\n",
       "  '<mask> Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. '),\n",
       " ('Just Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. ',\n",
       "  '<mask> Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. '),\n",
       " ('Just Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. ',\n",
       "  '<mask> Dance has always been banned in the Netherlands. The dance is a form of dance that is performed by a group of dancers. The dance is performed by a group of dancers. The dance is performed by a group of dancers. '),\n",
       " ('Sean Gunn is an American poet. He is the author of the forthcoming book, The Art of Poetry: A Poets Guide to the Art of Writing. The Art of Poetry is published by Penguin Random',\n",
       "  'Sean Gunn is an <mask> poet. He is the author of the forthcoming book, The Art of Poetry: A Poets Guide to the Art of Writing. The Art of Poetry is published by Penguin Random'),\n",
       " ('Chris Seibert has produced comedy programs. He has written and directed several films, including The Big Sick, The Big Sick 2, The Big Sick 3, The Big Sick 4',\n",
       "  '<mask> Seibert has produced comedy programs. He has written and directed several films, including The Big Sick, The Big Sick 2, The Big Sick 3, The Big Sick 4'),\n",
       " ('Konidela Motor Company was established. The Company is engaged in the production of various types of products and services. The Company is engaged in the production of various types of products and services. The Company is engaged in the production of various types',\n",
       "  'Konidela <mask> Company was established. The Company is engaged in the production of various types of products and services. The Company is engaged in the production of various types of products and services. The Company is engaged in the production of various types'),\n",
       " ('von von Hindenburg was a man. He was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was',\n",
       "  '<mask> von Hindenburg was a man. He was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was'),\n",
       " ('von von Hindenburg was a man. He was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was',\n",
       "  '<mask> von Hindenburg was a man. He was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was a man who was'),\n",
       " ('Vic Mensa was born June 12, 1993. He is the son of the late Paul and Mary Mensa. He is a graduate of the University of California, Berkeley. He is a member of the American Academy of Pediatrics, the American Academy',\n",
       "  'Vic Mensa was born <mask> 12, 1993. He is the son of the late Paul and Mary Mensa. He is a graduate of the University of California, Berkeley. He is a member of the American Academy of Pediatrics, the American Academy'),\n",
       " ('Mutiny on the Bounty is an American film. It is a story of a young man who is forced to choose between his family and his future. The film is based on the novel by the same name by the same name by the same name',\n",
       "  'Mutiny on the Bounty is an <mask> film. It is a story of a young man who is forced to choose between his family and his future. The film is based on the novel by the same name by the same name by the same name'),\n",
       " ('Color of Night came out in 1994. The film was directed by Michael Kors, who also directed the film. The film was released in the United States on June 1, 1994. The film was released in the United States on June',\n",
       "  'Color of Night came out in <mask>. The film was directed by Michael Kors, who also directed the film. The film was released in the United States on June 1, 1994. The film was released in the United States on June'),\n",
       " ('Color of Night came out in 1994. The film was directed by Michael Kors, who also directed the film. The film was released in the United States on June 1, 1994. The film was released in the United States on June',\n",
       "  'Color of Night came out in <mask>. The film was directed by Michael Kors, who also directed the film. The film was released in the United States on June 1, 1994. The film was released in the United States on June'),\n",
       " ('Death Note is a Japanese television drama series that first aired in 2009. It follows the life of a young boy who is forced to choose between his love for his father and his love for his mother. The series follows the life of a young boy',\n",
       "  'Death Note is a Japanese television drama series that first aired in <mask>. It follows the life of a young boy who is forced to choose between his love for his father and his love for his mother. The series follows the life of a young boy'),\n",
       " ('Death Note is a Japanese television drama series that first aired in 2009. It follows the life of a young boy who is forced to choose between his love for his father and his love for his mother. The series follows the life of a young boy',\n",
       "  'Death Note is a Japanese television drama series that first aired in <mask>. It follows the life of a young boy who is forced to choose between his love for his father and his love for his mother. The series follows the life of a young boy'),\n",
       " ('Nic Nicole Smith worked for multiple real estate companies. She was a member of the board of directors of the New York City real estate investment trust, which was founded in 1877. Smith was a member of the board of directors of the New York',\n",
       "  '<mask> Nicole Smith worked for multiple real estate companies. She was a member of the board of directors of the New York City real estate investment trust, which was founded in 1877. Smith was a member of the board of directors of the New York'),\n",
       " ('The Nobel Prize in Chemistry was awarded to a person from the Kingdom of Denmark. The prize was presented to the Nobel Laureate in Chemistry, Dr. Peter J. Koehler, who is also the Nobel Laureate in Chemistry. The',\n",
       "  'The Nobel Prize in Chemistry was awarded to a person from <mask> Kingdom of Denmark. The prize was presented to the Nobel Laureate in Chemistry, Dr. Peter J. Koehler, who is also the Nobel Laureate in Chemistry. The'),\n",
       " (\"Westworld (TV series)'s first season has an episode. The show, which is based on the real-life adventures of the late, great-grandmother of the late TV star, is based on the real-life adventures of the\",\n",
       "  \"Westworld (TV series)'s first season has <mask> episode. The show, which is based on the real-life adventures of the late, great-grandmother of the late TV star, is based on the real-life adventures of the\"),\n",
       " ('Manchester by the Shell is distributed by several large armadillos. The company has been in business since the early 1980s and has been a major player in the global maritime market. The company has been in business since the early 1980s',\n",
       "  'Manchester by the <mask> is distributed by several large armadillos. The company has been in business since the early 1980s and has been a major player in the global maritime market. The company has been in business since the early 1980s'),\n",
       " ('Manchester by the Shell is distributed by several large armadillos. The company has been in business since the early 1980s and has been a major player in the global maritime market. The company has been in business since the early 1980s',\n",
       "  'Manchester by the <mask> is distributed by several large armadillos. The company has been in business since the early 1980s and has been a major player in the global maritime market. The company has been in business since the early 1980s'),\n",
       " (\"Richard Dawson's date of birth was April 20, 1932. The couple's relationship was first reported by the New York Times in January. The couple's relationship was first reported by the New York Times in January. The couple's relationship was\",\n",
       "  \"Richard Dawson's date of birth was <mask> 20, 1932. The couple's relationship was first reported by the New York Times in January. The couple's relationship was first reported by the New York Times in January. The couple's relationship was\"),\n",
       " ('Pink is a pop singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for',\n",
       "  'Pink is a <mask> singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for'),\n",
       " ('Pink is a pop singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for',\n",
       "  'Pink is a <mask> singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for'),\n",
       " ('Pink is a pop singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for',\n",
       "  'Pink is a <mask> singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for'),\n",
       " ('Pink is a pop singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for',\n",
       "  'Pink is a <mask> singer. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for over 20 years. She is a singer who has been performing in the Netherlands for'),\n",
       " ('Hood Hood is the lowest point in its state. The state has been hit by a series of storms that have caused widespread flooding and mudslides. The storm has killed at least 12 people and displaced more than 200,000. The',\n",
       "  '<mask> Hood is the lowest point in its state. The state has been hit by a series of storms that have caused widespread flooding and mudslides. The storm has killed at least 12 people and displaced more than 200,000. The'),\n",
       " ('Pocahontas attended a masque at Whitehall Palace which was a place where mostly English people gathered. The Queen was also present at the event, which was attended by the Queens children, Prince William and Princess Charlotte.',\n",
       "  'Pocahontas attended a masque at Whitehall Palace which was a place where mostly <mask> people gathered. The Queen was also present at the event, which was attended by the Queens children, Prince William and Princess Charlotte.'),\n",
       " ('US Airways Flight 1549 had zero people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The',\n",
       "  'US Airways Flight 1549 had <mask> people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The'),\n",
       " ('US Airways Flight 1549 had zero people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The',\n",
       "  'US Airways Flight 1549 had <mask> people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The'),\n",
       " ('US Airways Flight 1549 had zero people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The',\n",
       "  'US Airways Flight 1549 had <mask> people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The'),\n",
       " ('US Airways Flight 1549 had zero people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The',\n",
       "  'US Airways Flight 1549 had <mask> people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The'),\n",
       " ('US Airways Flight 1549 had zero people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The',\n",
       "  'US Airways Flight 1549 had <mask> people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The'),\n",
       " ('US Airways Flight 1549 had zero people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The',\n",
       "  'US Airways Flight 1549 had <mask> people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The'),\n",
       " ('US Airways Flight 1549 had zero people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The',\n",
       "  'US Airways Flight 1549 had <mask> people on board. The plane was carrying 110 passengers and six crew members when it crashed. The plane was carrying 110 passengers and six crew members when it crashed. (Photo: Getty Images Europe) The'),\n",
       " ('Mom (TV series) has received a nomination. The show, which is based on the life of a former FBI agent, is based on the life of a former FBI agent who was killed in a car crash in the early 1990s. ',\n",
       "  'Mom (TV series) has received <mask> nomination. The show, which is based on the life of a former FBI agent, is based on the life of a former FBI agent who was killed in a car crash in the early 1990s. ')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(context['context_hypothesis'], context['masked_context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47fd7719baa4d75988ab986c858dd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cd014d1071433092b6d6ac45fc7e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  4.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2, 0, 0, 0, 0, 0, 0, 0, 2, 1],\n",
       " array([0., 2., 2., 2., 2., 2., 2., 2., 1., 0.]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.evaluate_dataset(filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QAPipeline:\n",
    "    \n",
    "    def __init__(self, question_tokenizer, question_generator, answer_tokenizer, answer_generator, \n",
    "                 mask_token: str = '[MASK]'):\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.question_tokenizer = question_tokenizer\n",
    "        self.question_generator = question_generator\n",
    "        self.answer_tokenizer = answer_tokenizer\n",
    "        self.answer_generator = answer_generator\n",
    "        self.max_len = min(question_tokenizer.model_max_length, answer_tokenizer.model_max_length)\n",
    "    \n",
    "    def __call__(self, dataset: Dataset = None, limit: int = 0, mask: bool = False, questionize: bool = False,\n",
    "                 answer: bool = False, save: bool = False, load: bool = False, \n",
    "                 path: str = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\" Performs all operations on the dataset \"\"\"\n",
    "        if (save or load) and not path:\n",
    "            raise ValueError(\"Must pass a path to save the processed dataset\")\n",
    "        \n",
    "        if load and os.path.exists(path):\n",
    "            dataset = load_dataset('csv', data_files=[path])['train']\n",
    "        \n",
    "        if dataset and not load:\n",
    "            mask = questionize = answer = True\n",
    "        \n",
    "        if limit != 0:\n",
    "            dataset = dataset.select(list(range(limit)))\n",
    "        \n",
    "        if mask:\n",
    "            print(\"Masking the claims and retrieving answers\")\n",
    "            dataset = dataset.map(self._mask)\n",
    "            dataset = dataset.filter(lambda x: x['target'] != None)\n",
    "        \n",
    "        if questionize:\n",
    "            print(\"Generating questions from the claims\")\n",
    "            dataset = self.generate_questions(dataset)\n",
    "            if save:\n",
    "                print(\"Saving checkpoint...\")\n",
    "                dataset.to_csv(path)\n",
    "                \n",
    "        if answer:\n",
    "            print(\"Answering the questions\")\n",
    "            dataset = self.fill_context(dataset)\n",
    "            if save:\n",
    "                print(\"Saving checkpoint...\")\n",
    "                dataset.to_csv(path)\n",
    "        return self.evaluate_dataset(dataset)\n",
    "    \n",
    "    def _mask(self, x: dict) -> dict:\n",
    "        \"\"\" Masks the last named entity in the string \"\"\"\n",
    "        x['answer'] = None\n",
    "        x['masked'] = None\n",
    "        x['label'] = self._map(x['label'])\n",
    "        claim = x['claim']\n",
    "        doc = self.nlp(claim, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "        ents = doc.ents\n",
    "        if ents:\n",
    "            answer = ents[0].text\n",
    "            masked = self.mask_token.join(claim.split(answer, 1))\n",
    "            x['answer'] = answer\n",
    "            x['masked'] = masked\n",
    "        return x\n",
    "        \n",
    "    def generate_questions(self, dataset: Dataset, limit: int = 0) -> Dataset:\n",
    "        \"\"\" Masks the entire dataset \"\"\"            \n",
    "        if limit != 0:\n",
    "            dataset = dataset.select(list(range(limit)))\n",
    "        data = dataset.map(self._questionize)\n",
    "        return data\n",
    "    \n",
    "    def _questionize(self, x: dict) -> dict:\n",
    "        \"\"\" Masks the claim and fills the mask \"\"\"\n",
    "        input_text = f\"<answer> {x['answer']} <context> {x['claim']} </s>\"\n",
    "        features = self.question_tokenizer([input_text], return_tensors='pt').to(self.device)\n",
    "        output = self.answer_generator.generate(input_ids=features['input_ids'], \n",
    "                                                attention_mask=features['attention_mask'],\n",
    "                                                max_length=self.max_len)\n",
    "        question = self.question_tokenizer.decode(output[0])\n",
    "        x['question'] = question.replace('question: ', '')\n",
    "        return x\n",
    "    \n",
    "    def generate_answers(self, dataset: Dataset, limit: int = 0) -> Dataset:\n",
    "        \"\"\" Masks the entire dataset \"\"\"            \n",
    "        if limit != 0:\n",
    "            dataset = dataset.select(list(range(limit)))\n",
    "        data = dataset.map(self._answer_question)\n",
    "        return data\n",
    "   \n",
    "    def _answer_question(self, x: dict) -> str:\n",
    "        \"\"\" Answers the question and fills the masked claim \"\"\"\n",
    "        input_ids = self.answer_tokenizer(x['question'], return_tensors=\"pt\").input_ids\n",
    "        pred_answer = self.answer_generator.generate(input_ids.to(self.device))[0]\n",
    "        response = self.answer_tokenizer.decode(gen_output, skip_special_tokens=True)\n",
    "        x['pred'] = response\n",
    "        x['hypothesis'] = x['masked'].replace(self.mask_token, response)\n",
    "        return x\n",
    "    \n",
    "    def evaluate_dataset(self, dataset: Dataset) -> Tuple[List[int], List[int]]:\n",
    "        \"\"\" Evaluates how well the model is able to predict \"\"\"\n",
    "        support = dataset.filter(lambda x: x['answer'] == x['pred'])\n",
    "        entail = dataset.filter(lambda x: x['answer'] != x['pred'])\n",
    "        assert support.shape[0] + entail.shape[0] == dataset.shape[0]\n",
    "        premise, hypothesis = entail['claim'], entail['hypothesis']\n",
    "        preds = torch.argmax(self.predict_batch(premise, hypothesis), dim=1)\n",
    "        \n",
    "        y_true = support['label']\n",
    "        y_true.extend(entail['label'])\n",
    "        y_pred = np.zeros(support.shape[0])\n",
    "        y_pred = np.concatenate((y_pred, preds), axis=None)\n",
    "        return y_true, y_pred\n",
    "    \n",
    "    def evaluate(self, y_true: List[int], y_pred: List[int]) -> tuple:\n",
    "        \"\"\" Evaluates how well the model is able to predict \"\"\"\n",
    "        metrics = precision_recall_fscore_support(y_true, y_pred)\n",
    "        macro = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        return metrics, macro, acc\n",
    "    \n",
    "    def _map(self, label: int) -> str:\n",
    "        \"\"\" Maps the label to the value \"\"\"\n",
    "        switcher = {\n",
    "            'SUPPORTS': 0,\n",
    "            'NOT ENOUGH INFO': 1,\n",
    "            'REFUTES': 2\n",
    "        }\n",
    "        return switcher[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2838e4ef0c4152b710dc613d74567e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1208.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e29d177962f48449eb70d32277846f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd41b89fcf684f47b88a613b2228d7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=39.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e643b23f5545a9bd5ce63ce1d254d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=121.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b344b38ec5a47a9993c68fc51eccda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87696a535944dd28aea9b07f18856f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891612736.0, style=ProgressStyle(descri"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "question_tokenizer = AutoTokenizer.from_pretrained(\"iarfmoose/t5-base-question-generator\")\n",
    "question_model = AutoModelWithLMHead.from_pretrained(\"iarfmoose/t5-base-question-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ae692b21b44c4abbbc70c4dc46fe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=571.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9386ce29cd964065baa2c1b128eb65bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0241763d754228bee33107e9a3bff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1786.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2baa6746c9ff456fa58dd0bc54ac5596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2067.0, style=ProgressStyle(description"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb9699d2764fb0b49ebcabbaf8b10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2950909652.0, style=ProgressStyle(descr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer_tokenizer = AutoTokenizer.from_pretrained(\"google/t5-large-ssm-nq\")\n",
    "answer_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5-large-ssm-nq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ffae63b4cb62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQAPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'question_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "pipe = QAPipeline(question_tokenizer, question_model, answer_tokenizer, answer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
