{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Custom Entailment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from models.textual_entailment import TextualEntailment\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "\n",
    "class Entailment:\n",
    "    \n",
    "    def __init__(self, load_elmo: bool = True, input_dim: int = 400, load_path: str = None):\n",
    "        self.input_dim = 400\n",
    "        self.path = load_path\n",
    "        if load_elmo:\n",
    "            self._frozen = Predictor.from_path(\"./models/textual_entailment.tar.gz\", cuda_device=0)\n",
    "        self._model = self._model()\n",
    "        \n",
    "    def _map(self, label: int) -> str:\n",
    "        \"\"\" Maps the label to the value \"\"\"\n",
    "        switcher = {\n",
    "            0: 'SUPPORT',\n",
    "            1: 'NOT ENOUGH INFORMATION',\n",
    "            2: 'REFUTED'\n",
    "        }\n",
    "        return switcher[label]\n",
    "\n",
    "    def _model(self) -> nn.Sequential:\n",
    "        \"\"\" Builds the MLP for the classification \"\"\"\n",
    "        if self.path:\n",
    "            return self.load()\n",
    "        \n",
    "        model = nn.Sequential(\n",
    "          nn.Linear(400,100),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(100,3),\n",
    "          nn.Softmax(dim=1)\n",
    "        )\n",
    "        model.cuda()\n",
    "        return model\n",
    "    \n",
    "    def save(self, path: str = './models/entailment.model') -> None:\n",
    "        \"\"\" Saves the model to the file \"\"\"\n",
    "        torch.save(self._model.state_dict(), path)\n",
    "        \n",
    "    def load(self, path: str = './models/entailment.model') -> bool:\n",
    "        \"\"\" Loads the model, if possible \"\"\"\n",
    "        if os.path.exists(path):\n",
    "            self._model.load_state_dict(torch.load(path))\n",
    "            return True\n",
    "        raise ValueError(f\"Path {path} is not valid\")\n",
    "\n",
    "    def entail_dataset(self, dataset: Dataset, batch_size: int = 50, \n",
    "                       total_size: int = 30000) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\" Entails all the data and returns the entailed texts \"\"\"\n",
    "        dataset = dataset.shuffle(seed=42)[:total_size]\n",
    "        X = self.entail_batch(dataset['premise'], dataset['hypothesis'], batch_size)\n",
    "        y = torch.tensor(dataset['label'])\n",
    "        return X, y\n",
    "    \n",
    "    def entail_batch(self, premises: List[str], hypotheses: List[str], batch_size: int = 50) -> np.ndarray:\n",
    "        \"\"\" Entails all the data and returns the entailed texts \"\"\"\n",
    "        batches = [dict(premise=v[0], hypothesis=v[1]) for v in zip(premises, hypotheses)]\n",
    "        total_size = len(batches)\n",
    "        \n",
    "        if total_size < batch_size:\n",
    "            batch_size = total_size\n",
    "            \n",
    "        iters = int(total_size / batch_size)\n",
    "        X = list()\n",
    "        \n",
    "        start = 0\n",
    "        for j in tqdm(range(iters)):\n",
    "            end = start + batch_size\n",
    "            batch_json = self._frozen.predict_batch_json(batches[start:end])\n",
    "            X.extend([e['aggregate_input'] for e in batch_json])\n",
    "            start = end\n",
    "        return torch.tensor(X)\n",
    "        \n",
    "    def predict(self, premises: List[str], hypotheses: List[str], batch_size: int = 50) -> torch.Tensor:\n",
    "        \"\"\" Predicts the next word for the text \"\"\"\n",
    "        embedding = self.entail_batch(premises, hypotheses)\n",
    "        embedding = embedding.cuda()\n",
    "        preds = self._model(embedding)\n",
    "        return preds\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray, y: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\" Evaluates the model on the test set \"\"\"\n",
    "        n, _ = X.size()\n",
    "        val = self._model(X)\n",
    "        preds = torch.argmax(val, dim=1)\n",
    "        total = float(sum(preds == y)) / n\n",
    "        return total\n",
    "\n",
    "    def fit(self, X_train: torch.Tensor, y_train: torch.Tensor, X_val: torch.Tensor, y_val: torch.Tensor, \n",
    "            batch_size: int = 32, epochs: int = 100, shuffle: bool = True) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\" Fits the data on the model \"\"\"\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self._model.parameters(), lr=1E-3)\n",
    "        \n",
    "        X_train = X_train.cuda()\n",
    "        y_train = y_train.long().cuda()\n",
    "        X_val = X_val.cuda()\n",
    "        y_val = y_val.long().cuda()\n",
    "        \n",
    "        n, _ = X_train.shape\n",
    "        tr_iters = int(n / batch_size)\n",
    "        \n",
    "        n, _ = X_val.shape\n",
    "        val_iters = int(n / batch_size)\n",
    "        \n",
    "        train_loss = np.zeros(epochs)\n",
    "        train_acc = np.zeros(epochs)\n",
    "        validation_loss = np.zeros(epochs)\n",
    "        validation_acc = np.zeros(epochs)\n",
    "        for epoch in range(epochs):\n",
    "            # Train and Validation Loss\n",
    "            total_loss = self._fit(X_train, y_train, criterion, optimizer, tr_iters, batch_size, shuffle)\n",
    "            val_loss = self._loss(X_val, y_val, criterion, val_iters, batch_size, shuffle)\n",
    "            \n",
    "            total_acc = self.evaluate(X_train, y_train)\n",
    "            val_acc = self.evaluate(X_val, y_val)\n",
    "            \n",
    "            print('[%d] loss: %.7f acc: %.7f \\t val_loss: %.7f val_acc: %.7f' % \n",
    "                  (epoch + 1, total_loss, total_acc, val_loss, val_acc)\n",
    "                 )\n",
    "            \n",
    "            train_loss[epoch] = total_loss\n",
    "            train_acc[epoch] = total_acc\n",
    "            \n",
    "            validation_loss[epoch] = val_loss\n",
    "            validation_acc[epoch] = val_acc\n",
    "        return train_loss, train_acc, validation_loss, validation_acc\n",
    "    \n",
    "    def _fit(self, X: torch.Tensor, y: torch.Tensor, criterion: nn.CrossEntropyLoss, \n",
    "             optimizer: optim.Adam, num_iters: int, batch_size: int = 32, \n",
    "             shuffle: bool = True) -> Tuple[float, float]:\n",
    "        \"\"\" Runs an epoch of training \"\"\"\n",
    "        total_loss = 0.0\n",
    "        if shuffle: \n",
    "            indices = np.random.permutation(range(X.shape[0]))\n",
    "        else:\n",
    "            indices = list(range(X.shape[0]))\n",
    "\n",
    "        start = 0\n",
    "        for i in range(num_iters):\n",
    "            end = start + batch_size\n",
    "            i = indices[start:end]\n",
    "            xi, yi = X[i], y[i]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = self._model(xi)\n",
    "            loss = criterion(outputs, yi)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            start = end\n",
    "\n",
    "        total_loss /= X.shape[0]\n",
    "        return total_loss\n",
    "    \n",
    "    def _loss(self, X: torch.Tensor, y: torch.Tensor, criterion: nn.CrossEntropyLoss, \n",
    "              num_iters: int, batch_size: int = 32, shuffle: bool = True) -> Tuple[float, float]:\n",
    "        \"\"\" Runs an epoch of training \"\"\"\n",
    "        total_loss = 0.0\n",
    "\n",
    "        if shuffle: \n",
    "            indices = np.random.permutation(range(X.shape[0]))\n",
    "        else:\n",
    "            indices = list(range(X.shape[0]))\n",
    "\n",
    "        start = 0\n",
    "        for i in range(num_iters):\n",
    "            end = start + batch_size\n",
    "            i = indices[start:end]\n",
    "            xi, yi = X[i], y[i]\n",
    "\n",
    "            # forward + loss\n",
    "            outputs = self._model(xi)\n",
    "            loss = criterion(outputs, yi)\n",
    "            total_loss += loss.item()\n",
    "            start = end\n",
    "        total_loss /= X.shape[0]\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/jmack/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "snli_data = load_dataset('snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550152, 3), (10000, 3), (10000, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli_data['train'].shape, snli_data['validation'].shape, snli_data['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailment = Entailment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: Do not run the below code unless you want to regenerate the entailments. **THIS TAKES A LONG TIME TO DO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def get_balanced_data(entailment: Entailment, data: Dataset) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\" Gets the training data for the entailment model \"\"\"\n",
    "    entailments = data.filter(lambda x: x['label'] == 0)\n",
    "    neutrals = data.filter(lambda x: x['label'] == 1)\n",
    "    contradictions = data.filter(lambda x: x['label'] == 2)\n",
    "    X_entail, y_entail = entailment.entail_dataset(entailments, batch_size=100, total_size=100000)\n",
    "    X_neutral, y_neutral = entailment.entail_dataset(neutrals, batch_size=100, total_size=100000)\n",
    "    X_contra, y_contra = entailment.entail_dataset(contradictions, batch_size=100, total_size=100000)\n",
    "    X_train = torch.vstack((X_entail, X_neutral))\n",
    "    X_train = torch.vstack((X_train, X_contra))\n",
    "    y_train = torch.hstack((y_entail, y_neutral))\n",
    "    y_train = torch.hstack((y_train, y_contra))\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = get_balanced_data(entailment, snli_data['train'])\n",
    "X_train.shape, y_train.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sum(y_train == 0), sum(y_train == 1), sum(y_train == 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x_train_path = './data/x_train.pt'\n",
    "torch.save(X_train, x_train_path)\n",
    "\n",
    "y_train_path = './data/y_train.pt'\n",
    "torch.save(y_train, y_train_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "total_val = snli_data['validation'].shape[0]\n",
    "X_val, y_val = entailment.entail_dataset(snli_data['validation'], batch_size=100, total_size=total_val)\n",
    "X_val.shape, y_val.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x_val_path = './data/x_validation.pt'\n",
    "torch.save(X_val, x_val_path)\n",
    "\n",
    "y_val_path = './data/y_validation.pt'\n",
    "torch.save(y_val, y_val_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "total_test = snli_data['test'].shape[0]\n",
    "X_test, y_test = entailment.entail_dataset(snli_data['test'], batch_size=100, total_size=total_test)\n",
    "X_test.shape, y_test.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x_test_path = './data/x_test.pt'\n",
    "torch.save(X_test, x_test_path)\n",
    "\n",
    "y_test_path = './data/y_test.pt'\n",
    "torch.save(y_test, y_test_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arrays(x_path: str, y_path: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    X = torch.load(x_path)\n",
    "    y = torch.load(y_path)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300000, 400]), torch.Size([300000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_path = './data/x_train.pt'\n",
    "y_train_path = './data/y_train.pt'\n",
    "\n",
    "X_train, y_train = load_arrays(x_train_path, y_train_path)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(100000), tensor(100000), tensor(100000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train == 0), sum(y_train == 1), sum(y_train == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9842, 400]), torch.Size([9842]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_path = './data/x_validation.pt'\n",
    "y_val_path = './data/y_validation.pt'\n",
    "\n",
    "X_val, y_val = load_arrays(x_val_path, y_val_path)\n",
    "\n",
    "pos = torch.nonzero(y_val != -1)  # Remove -1\n",
    "pos = pos.reshape(pos.size()[0])  # Remove -1\n",
    "\n",
    "X_val = X_val[pos]\n",
    "y_val = y_val[pos]\n",
    "\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3329), tensor(3235))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_val == 0), sum(y_val == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9824, 400]), torch.Size([9824]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_path = './data/x_test.pt'\n",
    "y_test_path = './data/y_test.pt'\n",
    "\n",
    "X_test, y_test = load_arrays(x_test_path, y_test_path)\n",
    "\n",
    "pos = torch.nonzero(y_test != -1)  # Remove -1\n",
    "pos = pos.reshape(pos.size()[0])  # Remove -1\n",
    "\n",
    "X_test = X_test[pos]\n",
    "y_test = y_test[pos]\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3368), tensor(3219))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test == 0), sum(y_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailment = Entailment(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.0205498 acc: 0.8902500 \t val_loss: 0.0217112 val_acc: 0.8902500\n",
      "[2] loss: 0.0203360 acc: 0.9011433 \t val_loss: 0.0213159 val_acc: 0.9011433\n",
      "[3] loss: 0.0202859 acc: 0.9009300 \t val_loss: 0.0213976 val_acc: 0.9009300\n",
      "[4] loss: 0.0202514 acc: 0.9039433 \t val_loss: 0.0214007 val_acc: 0.9039433\n",
      "[5] loss: 0.0202195 acc: 0.9046733 \t val_loss: 0.0213258 val_acc: 0.9046733\n",
      "[6] loss: 0.0201945 acc: 0.9060600 \t val_loss: 0.0212593 val_acc: 0.9060600\n",
      "[7] loss: 0.0201695 acc: 0.9058400 \t val_loss: 0.0213143 val_acc: 0.9058400\n",
      "[8] loss: 0.0201569 acc: 0.9072133 \t val_loss: 0.0212545 val_acc: 0.9072133\n",
      "[9] loss: 0.0201347 acc: 0.9043167 \t val_loss: 0.0212862 val_acc: 0.9043167\n",
      "[10] loss: 0.0201164 acc: 0.9080133 \t val_loss: 0.0213465 val_acc: 0.9080133\n",
      "[11] loss: 0.0200967 acc: 0.9071600 \t val_loss: 0.0213771 val_acc: 0.9071600\n",
      "[12] loss: 0.0200894 acc: 0.9078900 \t val_loss: 0.0212464 val_acc: 0.9078900\n",
      "[13] loss: 0.0200703 acc: 0.9106733 \t val_loss: 0.0213038 val_acc: 0.9106733\n",
      "[14] loss: 0.0200538 acc: 0.9087800 \t val_loss: 0.0212874 val_acc: 0.9087800\n",
      "[15] loss: 0.0200410 acc: 0.9102833 \t val_loss: 0.0212968 val_acc: 0.9102833\n",
      "[16] loss: 0.0200252 acc: 0.9069200 \t val_loss: 0.0212473 val_acc: 0.9069200\n",
      "[17] loss: 0.0200199 acc: 0.9125800 \t val_loss: 0.0212783 val_acc: 0.9125800\n",
      "[18] loss: 0.0200050 acc: 0.9116067 \t val_loss: 0.0212658 val_acc: 0.9116067\n",
      "[19] loss: 0.0199841 acc: 0.9111933 \t val_loss: 0.0213221 val_acc: 0.9111933\n",
      "[20] loss: 0.0199731 acc: 0.9093967 \t val_loss: 0.0213644 val_acc: 0.9093967\n",
      "[21] loss: 0.0199634 acc: 0.9127967 \t val_loss: 0.0213477 val_acc: 0.9127967\n",
      "[22] loss: 0.0199444 acc: 0.9130767 \t val_loss: 0.0213151 val_acc: 0.9130767\n",
      "[23] loss: 0.0199377 acc: 0.9142433 \t val_loss: 0.0213470 val_acc: 0.9142433\n",
      "[24] loss: 0.0199081 acc: 0.9140200 \t val_loss: 0.0213395 val_acc: 0.9140200\n",
      "[25] loss: 0.0199057 acc: 0.9146800 \t val_loss: 0.0213545 val_acc: 0.9146800\n",
      "[26] loss: 0.0198911 acc: 0.9171400 \t val_loss: 0.0213283 val_acc: 0.9171400\n",
      "[27] loss: 0.0198760 acc: 0.9159100 \t val_loss: 0.0212743 val_acc: 0.9159100\n",
      "[28] loss: 0.0198601 acc: 0.9156100 \t val_loss: 0.0213628 val_acc: 0.9156100\n",
      "[29] loss: 0.0198519 acc: 0.9171367 \t val_loss: 0.0213380 val_acc: 0.9171367\n",
      "[30] loss: 0.0198329 acc: 0.9184600 \t val_loss: 0.0213565 val_acc: 0.9184600\n",
      "[31] loss: 0.0198207 acc: 0.9182267 \t val_loss: 0.0214104 val_acc: 0.9182267\n",
      "[32] loss: 0.0198169 acc: 0.9181833 \t val_loss: 0.0213694 val_acc: 0.9181833\n",
      "[33] loss: 0.0198017 acc: 0.9175700 \t val_loss: 0.0213902 val_acc: 0.9175700\n",
      "[34] loss: 0.0197938 acc: 0.9128100 \t val_loss: 0.0214537 val_acc: 0.9128100\n",
      "[35] loss: 0.0197928 acc: 0.9194467 \t val_loss: 0.0213656 val_acc: 0.9194467\n",
      "[36] loss: 0.0197719 acc: 0.9188567 \t val_loss: 0.0214116 val_acc: 0.9188567\n",
      "[37] loss: 0.0197659 acc: 0.9197400 \t val_loss: 0.0213715 val_acc: 0.9197400\n",
      "[38] loss: 0.0197517 acc: 0.9192900 \t val_loss: 0.0214304 val_acc: 0.9192900\n",
      "[39] loss: 0.0197400 acc: 0.9207767 \t val_loss: 0.0214206 val_acc: 0.9207767\n",
      "[40] loss: 0.0197407 acc: 0.9203467 \t val_loss: 0.0213865 val_acc: 0.9203467\n",
      "[41] loss: 0.0197290 acc: 0.9198200 \t val_loss: 0.0213755 val_acc: 0.9198200\n",
      "[42] loss: 0.0197292 acc: 0.9209300 \t val_loss: 0.0213598 val_acc: 0.9209300\n",
      "[43] loss: 0.0197140 acc: 0.9205467 \t val_loss: 0.0213967 val_acc: 0.9205467\n",
      "[44] loss: 0.0197062 acc: 0.9213400 \t val_loss: 0.0213973 val_acc: 0.9213400\n",
      "[45] loss: 0.0196949 acc: 0.9195333 \t val_loss: 0.0214011 val_acc: 0.9195333\n",
      "[46] loss: 0.0196941 acc: 0.9227400 \t val_loss: 0.0213640 val_acc: 0.9227400\n",
      "[47] loss: 0.0196710 acc: 0.9221800 \t val_loss: 0.0213940 val_acc: 0.9221800\n",
      "[48] loss: 0.0196699 acc: 0.9241667 \t val_loss: 0.0213634 val_acc: 0.9241667\n",
      "[49] loss: 0.0196667 acc: 0.9207467 \t val_loss: 0.0214480 val_acc: 0.9207467\n",
      "[50] loss: 0.0196644 acc: 0.9233533 \t val_loss: 0.0214303 val_acc: 0.9233533\n"
     ]
    }
   ],
   "source": [
    "loss, acc, val_loss, val_acc = entailment.fit(X_train, y_train, X_val, y_val, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = list(range(50))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8540309446254072"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment.evaluate(X_test.cuda(), y_test.long().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Path None is not valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-47a2e0d3cceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntailment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-7b983342f25c>\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Path {self.path} is not valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     def entail_dataset(self, dataset: Dataset, batch_size: int = 50, \n",
      "\u001b[0;31mValueError\u001b[0m: Path None is not valid"
     ]
    }
   ],
   "source": [
    "model = Entailment(False)\n",
    "model.load()\n",
    "model.evaluate(X_test.cuda(), y_test.long().cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Facebook Experiment\n",
    "\n",
    "1. Implement automatic masking\n",
    "2. Get the top 1 prediction from the LM \n",
    "3. Fill in the mask\n",
    "4. Use the claim and filled in sentence and input into an entailment model\n",
    "5. Input entailment into MLP for final fact-verification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import Iterable\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    def __init__(self, tokenizer, unmasker, predictor, mask_token: str = \"[MASK]\"):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.mask_token = mask_token\n",
    "        self.tokenizer = tokenizer\n",
    "        self.unmasker = unmasker\n",
    "        self.model = predictor\n",
    "    \n",
    "    def _mask(self, texts: List[str]) -> List[str]:\n",
    "        \"\"\" Masks the last named entity in the string \"\"\"\n",
    "        masked_sents = list()\n",
    "        for doc in self.nlp.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "            ents = doc.ents\n",
    "            target = ents[-1].text.split()[-1]\n",
    "            if self.tokenizer.vocab.get(target):  # If the target is not in the vocab, skip the entry\n",
    "                masked = doc.text.replace(target, mask_token)\n",
    "                masked_sents.append(masked)\n",
    "        return masked_sents\n",
    "    \n",
    "    def _fill_mask(self, texts: Iterable) -> List[str]:\n",
    "        \"\"\" Fills the masked token with the  top-1 predicted value \"\"\"\n",
    "        preds = list()\n",
    "        for text in texts:\n",
    "            tokens = self.tokenizer(text, return_tensors='tf')['input_ids']\n",
    "            masked_index = tf.where(tokens[0] == self.tokenizer.mask_token_id).numpy()\n",
    "\n",
    "            outputs = self.unmasker(tokens)\n",
    "            logits = outputs.logits[0, masked_index.item(), :]\n",
    "            probs = tf.nn.softmax(logits)\n",
    "            topk = tf.math.top_k(probs, k=1)\n",
    "            values, predictions = topk.values.numpy(), topk.indices.numpy()\n",
    "            \n",
    "            pred = tokenizer.decode(predictions)\n",
    "            preds.append(text.replace(self.mask_token, pred))\n",
    "        return preds\n",
    "    \n",
    "    def forward(self, claims: List[str]) -> np.ndarray:\n",
    "        \"\"\" Predicts the next word for the text \"\"\"\n",
    "        masked = self._mask(texts)\n",
    "        claims = self._fill_mask(masked)\n",
    "        preds = self.model.predict(texts, claims)\n",
    "        return preds\n",
    "    \n",
    "    def evaluate(self, claims: List[str], labels: List[str]) -> Tuple[float, float, float, float]\n",
    "        \"\"\" Evaluates how well the model is able to predict \"\"\"\n",
    "        y_true = np.array([self._map(label) for label in labels])\n",
    "        y_pred = np.argmax(self.forward(claims), axis=1)\n",
    "        precision, recall, f1 = precision_recall_fscore_support(y_true, y_pred)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        return acc, precision, recall, f1\n",
    "    \n",
    "    def _map(self, label: int) -> str:\n",
    "        \"\"\" Maps the label to the value \"\"\"\n",
    "        switcher = {\n",
    "            'SUPPORT': 0,\n",
    "            'NOT ENOUGH INFORMATION': 1,\n",
    "            'REFUTED': 2\n",
    "        }\n",
    "        return switcher[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entailment(load_path='./models/entailment.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-large-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "unmasker = TFBertForMaskedLM.from_pretrained('bert-large-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"Thomas Jefferson founded the University of Virginia after retiring.\"\n",
    "test2 = \"Microsoft's headquarters are in Redmond.\"\n",
    "test3 = \"Tim Roth is an English actor.\"\n",
    "texts = [test1,test2,test3]\n",
    "mask_token = \"[MASK]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(tokenizer, unmasker, model)\n",
    "pipe.forward(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset fever/v1.0 (download: 42.78 MiB, generated: 38.39 MiB, post-processed: Unknown size, total: 81.17 MiB) to /home/jmack/.cache/huggingface/datasets/fever/v1.0/1.0.0/fe391c4f48669454ae0d368997430e6fa476aacb476d930d3328b67356e74625...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc6268193f14313804ac3034d147332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=33024303.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03d7f2ee8e249d8b3b098e93710cbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=4349935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4eed32fe0949aaaf53d210b5bd9afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1530640.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b09e614deb481186402373a29595f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1599159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858fb0fec884409e83baaadf86e6fa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=2168767.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc93a82cb1e148788deb94a33f94dc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=2181168.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset fever downloaded and prepared to /home/jmack/.cache/huggingface/datasets/fever/v1.0/1.0.0/fe391c4f48669454ae0d368997430e6fa476aacb476d930d3328b67356e74625. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('fever', 'v1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': ['Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.',\n",
       "  'Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.',\n",
       "  'Roman Atwood is a content creator.',\n",
       "  'Roman Atwood is a content creator.',\n",
       "  'History of art includes architecture, dance, sculpture, music, painting, poetry literature, theatre, narrative, film, photography and graphic arts.'],\n",
       " 'evidence_annotation_id': [92206, 92206, 174271, 174271, 255136],\n",
       " 'evidence_id': [104971, 104971, 187498, 187499, 254645],\n",
       " 'evidence_sentence_id': [7, -1, 1, 3, 2],\n",
       " 'evidence_wiki_url': ['Nikolaj_Coster-Waldau',\n",
       "  'Fox_Broadcasting_Company',\n",
       "  'Roman_Atwood',\n",
       "  'Roman_Atwood',\n",
       "  'History_of_art'],\n",
       " 'id': [75397, 75397, 150448, 150448, 214861],\n",
       " 'label': ['SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS']}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(texts, filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.0920089e-16],\n",
       "       [2.7299342e-01],\n",
       "       [9.9992239e-01]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import Iterable\n",
    "\n",
    "NLP = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "def mask_last_named_entity(texts: Iterable, mask_token: str = \"[MASK]\") -> str:\n",
    "    \"\"\" Masks the last named entity in the string \"\"\"\n",
    "    masked_sents = list()\n",
    "    for doc in NLP.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "        ents = doc.ents\n",
    "        target = ents[-1].text.split()[-1]\n",
    "        masked = doc.text.replace(target, mask_token)\n",
    "        masked_sents.append(masked)\n",
    "    return masked_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas Jefferson founded the University of [MASK] after retiring.',\n",
       " \"Microsoft's headquarters are in [MASK].\",\n",
       " 'Tim Roth is an [MASK] actor.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked = mask_last_named_entity([test1, test2, test3], mask_token) \n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tokenizer, model, sentences: list) -> list:\n",
    "    filled = list()\n",
    "    for sent in sentences:\n",
    "        tokens = tokenizer(sent, return_tensors='tf')['input_ids']\n",
    "        masked_index = tf.where(tokens[0] == tokenizer.mask_token_id).numpy()\n",
    "        \n",
    "        outputs = model(tokens)\n",
    "        logits = outputs.logits[0, masked_index.item(), :]\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        topk = tf.math.top_k(probs, k=1)\n",
    "        values, predictions = topk.values.numpy(), topk.indices.numpy()\n",
    "        \n",
    "        pred = tokenizer.decode(predictions)\n",
    "        filled.append(sent.replace('[MASK]', pred))\n",
    "    return filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas Jefferson founded the University of Virginia after retiring.',\n",
       " \"Microsoft's headquarters are in Atlanta.\",\n",
       " 'Tim Roth is an American actor.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(tokenizer, model, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = predictor.predict(\n",
    "        premise=\"Two women are wandering along the shore drinking iced tea.\",\n",
    "        hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = np.array([outputs['aggregate_input']])\n",
    "model_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,201\n",
      "Trainable params: 40,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(400,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1E-3), loss='binary_crossentropy', \n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64905727]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lerc is not a registered model.\n",
      "roberta-rte is not a registered model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'textual_entailment'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp_models import pretrained\n",
    "\n",
    "pretrained.get_pretrained_models()['pair-classification-decomposable-attention-elmo'].task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 6 required positional arguments: 'vocab', 'text_field_embedder', 'attend_feedforward', 'matrix_attention', 'compare_feedforward', and 'aggregate_feedforward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-cd6fa6b91752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpair_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecomposableAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecomposableAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 6 required positional arguments: 'vocab', 'text_field_embedder', 'attend_feedforward', 'matrix_attention', 'compare_feedforward', and 'aggregate_feedforward'"
     ]
    }
   ],
   "source": [
    "from allennlp_models.pair_classification.models import DecomposableAttention\n",
    "\n",
    "model = DecomposableAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lerc is not a registered model.\n",
      "roberta-rte is not a registered model.\n"
     ]
    }
   ],
   "source": [
    "pred = pretrained.load_predictor('pair-classification-decomposable-attention-elmo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pred.predict(\n",
    "        premise=\"Two women are wandering along the shore drinking iced tea.\",\n",
    "        hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_logits': [-3.349437952041626, 4.429553985595703, 0.9683454036712646],\n",
       " 'label_probs': [0.00040553370490670204,\n",
       "  0.9691703915596008,\n",
       "  0.030424002557992935],\n",
       " 'h2p_attention': [[0.6542813777923584,\n",
       "   0.04181642830371857,\n",
       "   0.044751670211553574,\n",
       "   0.04774125665426254,\n",
       "   0.032621681690216064,\n",
       "   0.02951720543205738,\n",
       "   0.0222022645175457,\n",
       "   0.02251223288476467,\n",
       "   0.022536294534802437,\n",
       "   0.03395495191216469,\n",
       "   0.025392329320311546,\n",
       "   0.02267230674624443],\n",
       "  [2.8718852263409644e-05,\n",
       "   0.9997602105140686,\n",
       "   2.671044239832554e-05,\n",
       "   3.0569222872145474e-05,\n",
       "   1.630610495340079e-05,\n",
       "   1.6656915249768645e-05,\n",
       "   2.2438669475377537e-05,\n",
       "   1.677172986092046e-05,\n",
       "   1.8310134692001157e-05,\n",
       "   3.356780143803917e-05,\n",
       "   1.4835497495369054e-05,\n",
       "   1.4929611097613815e-05],\n",
       "  [0.10177356749773026,\n",
       "   0.08759545534849167,\n",
       "   0.1118234395980835,\n",
       "   0.11648961156606674,\n",
       "   0.08897500485181808,\n",
       "   0.10866256058216095,\n",
       "   0.06278194487094879,\n",
       "   0.06688541173934937,\n",
       "   0.06301344931125641,\n",
       "   0.07898420095443726,\n",
       "   0.06009376421570778,\n",
       "   0.05292144790291786],\n",
       "  [0.0004623697604984045,\n",
       "   0.0005366479163058102,\n",
       "   0.0013094748137518764,\n",
       "   0.9844369888305664,\n",
       "   0.0037109607364982367,\n",
       "   0.0008001072565093637,\n",
       "   0.000759141577873379,\n",
       "   0.00399616826325655,\n",
       "   0.0005880572716705501,\n",
       "   0.0022712009958922863,\n",
       "   0.0006370970513671637,\n",
       "   0.0004917914629913867],\n",
       "  [0.021879466250538826,\n",
       "   0.016263877972960472,\n",
       "   0.043620962649583817,\n",
       "   0.3232453167438507,\n",
       "   0.12519335746765137,\n",
       "   0.21580788493156433,\n",
       "   0.03572555258870125,\n",
       "   0.09783807396888733,\n",
       "   0.03638046607375145,\n",
       "   0.04659603163599968,\n",
       "   0.022638076916337013,\n",
       "   0.014810925349593163],\n",
       "  [0.017246725037693977,\n",
       "   0.011929051950573921,\n",
       "   0.031438130885362625,\n",
       "   0.2378472089767456,\n",
       "   0.06237583979964256,\n",
       "   0.4272131025791168,\n",
       "   0.038840629160404205,\n",
       "   0.05050673708319664,\n",
       "   0.05539732053875923,\n",
       "   0.04054877907037735,\n",
       "   0.016226788982748985,\n",
       "   0.010429643094539642],\n",
       "  [0.0102377999573946,\n",
       "   0.010660983622074127,\n",
       "   0.012148184701800346,\n",
       "   0.4098280966281891,\n",
       "   0.024485282599925995,\n",
       "   0.049786731600761414,\n",
       "   0.36476778984069824,\n",
       "   0.028135929256677628,\n",
       "   0.031522396951913834,\n",
       "   0.043300505727529526,\n",
       "   0.008045729249715805,\n",
       "   0.007080606184899807],\n",
       "  [0.012575305067002773,\n",
       "   0.013238711282610893,\n",
       "   0.032401192933321,\n",
       "   0.24183233082294464,\n",
       "   0.13379737734794617,\n",
       "   0.3817344009876251,\n",
       "   0.06835024803876877,\n",
       "   0.05440527945756912,\n",
       "   0.015210701152682304,\n",
       "   0.02560754492878914,\n",
       "   0.012246701866388321,\n",
       "   0.008600177243351936],\n",
       "  [0.02550632879137993,\n",
       "   0.02194177731871605,\n",
       "   0.04952565208077431,\n",
       "   0.0795864388346672,\n",
       "   0.0690709576010704,\n",
       "   0.5571142435073853,\n",
       "   0.05692204087972641,\n",
       "   0.03753482177853584,\n",
       "   0.030629552900791168,\n",
       "   0.04115668684244156,\n",
       "   0.017573071643710136,\n",
       "   0.013438398018479347],\n",
       "  [0.0032999140676110983,\n",
       "   0.0037106797099113464,\n",
       "   0.00489591620862484,\n",
       "   0.01287841983139515,\n",
       "   0.009935688227415085,\n",
       "   0.050064265727996826,\n",
       "   0.6458783745765686,\n",
       "   0.012672769837081432,\n",
       "   0.16958104074001312,\n",
       "   0.08052573353052139,\n",
       "   0.0033406356815248728,\n",
       "   0.0032165131997317076],\n",
       "  [0.011913090944290161,\n",
       "   0.009290369227528572,\n",
       "   0.0199927669018507,\n",
       "   0.42288175225257874,\n",
       "   0.02823151834309101,\n",
       "   0.02082984149456024,\n",
       "   0.014663374982774258,\n",
       "   0.33708497881889343,\n",
       "   0.058575790375471115,\n",
       "   0.05190961807966232,\n",
       "   0.017143506556749344,\n",
       "   0.007483404595404863],\n",
       "  [0.028186608105897903,\n",
       "   0.025777099654078484,\n",
       "   0.05010043457150459,\n",
       "   0.40535101294517517,\n",
       "   0.07974492758512497,\n",
       "   0.07758960872888565,\n",
       "   0.0279350895434618,\n",
       "   0.1694972813129425,\n",
       "   0.04901993274688721,\n",
       "   0.05365008860826492,\n",
       "   0.021943798288702965,\n",
       "   0.011204180307686329],\n",
       "  [0.003791020717471838,\n",
       "   0.0037876616697758436,\n",
       "   0.005148179829120636,\n",
       "   0.04601581394672394,\n",
       "   0.007641100324690342,\n",
       "   0.009489400312304497,\n",
       "   0.01279785018414259,\n",
       "   0.11390943080186844,\n",
       "   0.20984220504760742,\n",
       "   0.5805724263191223,\n",
       "   0.0038965558633208275,\n",
       "   0.0031084204092621803],\n",
       "  [0.07601422071456909,\n",
       "   0.06725233048200607,\n",
       "   0.08519984036684036,\n",
       "   0.13195280730724335,\n",
       "   0.07711151987314224,\n",
       "   0.08093569427728653,\n",
       "   0.0706259161233902,\n",
       "   0.09599754959344864,\n",
       "   0.08104491233825684,\n",
       "   0.07409657537937164,\n",
       "   0.09086937457323074,\n",
       "   0.06889919191598892],\n",
       "  [0.08347291499376297,\n",
       "   0.08220735937356949,\n",
       "   0.08219696581363678,\n",
       "   0.08517542481422424,\n",
       "   0.07966078072786331,\n",
       "   0.08381462097167969,\n",
       "   0.0845530554652214,\n",
       "   0.08125219494104385,\n",
       "   0.08679300546646118,\n",
       "   0.0875125303864479,\n",
       "   0.08170206844806671,\n",
       "   0.08165907859802246]],\n",
       " 'p2h_attention': [[0.5794978737831116,\n",
       "   0.038077544420957565,\n",
       "   0.037115372717380524,\n",
       "   0.01881016418337822,\n",
       "   0.02877109684050083,\n",
       "   0.03250500187277794,\n",
       "   0.0274263434112072,\n",
       "   0.028178894892334938,\n",
       "   0.03750938922166824,\n",
       "   0.02097991108894348,\n",
       "   0.03461119532585144,\n",
       "   0.050881993025541306,\n",
       "   0.024034641683101654,\n",
       "   0.02161012962460518,\n",
       "   0.01999048702418804],\n",
       "  [2.7932510420214385e-05,\n",
       "   0.9997096061706543,\n",
       "   2.4092194507829845e-05,\n",
       "   1.646525925025344e-05,\n",
       "   1.6129462892422453e-05,\n",
       "   1.6956086255959235e-05,\n",
       "   2.1539437511819415e-05,\n",
       "   2.2373153115040623e-05,\n",
       "   2.4335489797522314e-05,\n",
       "   1.7792224753065966e-05,\n",
       "   2.0356405002530664e-05,\n",
       "   3.509387170197442e-05,\n",
       "   1.8110436940332875e-05,\n",
       "   1.4419360013562255e-05,\n",
       "   1.4847881175228395e-05],\n",
       "  [0.055058859288692474,\n",
       "   0.04919420927762985,\n",
       "   0.05664772167801857,\n",
       "   0.07399989664554596,\n",
       "   0.07967934757471085,\n",
       "   0.082305908203125,\n",
       "   0.04520675912499428,\n",
       "   0.10085493326187134,\n",
       "   0.10117033123970032,\n",
       "   0.043238017708063126,\n",
       "   0.0806855633854866,\n",
       "   0.12563005089759827,\n",
       "   0.04533838480710983,\n",
       "   0.03364589437842369,\n",
       "   0.027344146743416786],\n",
       "  [0.0009355745278298855,\n",
       "   0.000896776095032692,\n",
       "   0.0009399468544870615,\n",
       "   0.8861116766929626,\n",
       "   0.009404795244336128,\n",
       "   0.009918340481817722,\n",
       "   0.024291837587952614,\n",
       "   0.011989947408437729,\n",
       "   0.002589575247839093,\n",
       "   0.0018115945858880877,\n",
       "   0.027183692902326584,\n",
       "   0.01619011163711548,\n",
       "   0.006454849150031805,\n",
       "   0.0008300007320940495,\n",
       "   0.0004513250896707177],\n",
       "  [0.021218551322817802,\n",
       "   0.015877211466431618,\n",
       "   0.023829173296689987,\n",
       "   0.11086936295032501,\n",
       "   0.12089911103248596,\n",
       "   0.08633403480052948,\n",
       "   0.04817131906747818,\n",
       "   0.22017863392829895,\n",
       "   0.07459499686956406,\n",
       "   0.04638965427875519,\n",
       "   0.060234926640987396,\n",
       "   0.10571739077568054,\n",
       "   0.035576194524765015,\n",
       "   0.01609918661415577,\n",
       "   0.014010204002261162],\n",
       "  [0.007183174602687359,\n",
       "   0.006068067625164986,\n",
       "   0.01088811457157135,\n",
       "   0.008943452499806881,\n",
       "   0.0779723972082138,\n",
       "   0.2212289720773697,\n",
       "   0.03664618358016014,\n",
       "   0.23502855002880096,\n",
       "   0.22510765492916107,\n",
       "   0.08745463192462921,\n",
       "   0.016627691686153412,\n",
       "   0.0384838730096817,\n",
       "   0.016530055552721024,\n",
       "   0.0063220299780368805,\n",
       "   0.005515076220035553],\n",
       "  [0.0034150348510593176,\n",
       "   0.005166654475033283,\n",
       "   0.00397616159170866,\n",
       "   0.0053633530624210835,\n",
       "   0.008158475160598755,\n",
       "   0.01271277666091919,\n",
       "   0.16970250010490417,\n",
       "   0.026598431169986725,\n",
       "   0.01453727763146162,\n",
       "   0.713119387626648,\n",
       "   0.007398379035294056,\n",
       "   0.008757534436881542,\n",
       "   0.014090587384998798,\n",
       "   0.0034868817310780287,\n",
       "   0.003516556229442358],\n",
       "  [0.007020140998065472,\n",
       "   0.00782924797385931,\n",
       "   0.008587962947785854,\n",
       "   0.05723832547664642,\n",
       "   0.045296810567379,\n",
       "   0.03351450338959694,\n",
       "   0.02653764933347702,\n",
       "   0.042922645807266235,\n",
       "   0.019434189423918724,\n",
       "   0.028366943821310997,\n",
       "   0.3448033630847931,\n",
       "   0.10772685706615448,\n",
       "   0.25426188111305237,\n",
       "   0.009608656167984009,\n",
       "   0.006850983947515488],\n",
       "  [0.006401711143553257,\n",
       "   0.007786095142364502,\n",
       "   0.007370183244347572,\n",
       "   0.007672714535146952,\n",
       "   0.01534313801676035,\n",
       "   0.03348563611507416,\n",
       "   0.0270836241543293,\n",
       "   0.0109315300360322,\n",
       "   0.014446379616856575,\n",
       "   0.3457837700843811,\n",
       "   0.05458037927746773,\n",
       "   0.02838052064180374,\n",
       "   0.4266784191131592,\n",
       "   0.007389492355287075,\n",
       "   0.006666360888630152],\n",
       "  [0.005955484230071306,\n",
       "   0.00881356280297041,\n",
       "   0.005704079754650593,\n",
       "   0.01829722709953785,\n",
       "   0.01213375199586153,\n",
       "   0.015133792534470558,\n",
       "   0.022971050813794136,\n",
       "   0.011363179422914982,\n",
       "   0.011985580436885357,\n",
       "   0.10138233751058578,\n",
       "   0.029865272343158722,\n",
       "   0.019178668037056923,\n",
       "   0.7288942933082581,\n",
       "   0.004171451088041067,\n",
       "   0.004150253254920244],\n",
       "  [0.055401433259248734,\n",
       "   0.0484546460211277,\n",
       "   0.05398578941822052,\n",
       "   0.06384691596031189,\n",
       "   0.07333149760961533,\n",
       "   0.07533685117959976,\n",
       "   0.05309552699327469,\n",
       "   0.06760141998529434,\n",
       "   0.0636606439948082,\n",
       "   0.052319228649139404,\n",
       "   0.12269391119480133,\n",
       "   0.09758078306913376,\n",
       "   0.06085463985800743,\n",
       "   0.06363722681999207,\n",
       "   0.04819945618510246],\n",
       "  [0.06747952848672867,\n",
       "   0.06651806831359863,\n",
       "   0.06485441327095032,\n",
       "   0.06723154336214066,\n",
       "   0.06544717401266098,\n",
       "   0.06605444103479385,\n",
       "   0.0637412816286087,\n",
       "   0.0647592544555664,\n",
       "   0.06640926003456116,\n",
       "   0.06871878355741501,\n",
       "   0.07306013256311417,\n",
       "   0.0679658055305481,\n",
       "   0.06622321903705597,\n",
       "   0.06582117825746536,\n",
       "   0.06571603566408157]],\n",
       " 'premise_tokens': ['Two',\n",
       "  'women',\n",
       "  'are',\n",
       "  'wandering',\n",
       "  'along',\n",
       "  'the',\n",
       "  'shore',\n",
       "  'drinking',\n",
       "  'iced',\n",
       "  'tea',\n",
       "  '.',\n",
       "  '@@NULL@@'],\n",
       " 'hypothesis_tokens': ['Two',\n",
       "  'women',\n",
       "  'are',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'a',\n",
       "  'blanket',\n",
       "  'near',\n",
       "  'some',\n",
       "  'rocks',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'politics',\n",
       "  '.',\n",
       "  '@@NULL@@'],\n",
       " 'label': 'contradiction'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAMA Probe into BART\n",
    "\n",
    "The goal of this section is to understand the amount of knowledge stored in BART using the [LAMA probe](https://github.com/facebookresearch/LAMA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lama_data = load_dataset('lama')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From BERT to BART\n",
    "\n",
    "Insert the BART model in lieu of BERT to see if performance increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting a Context Layer into the Pipeline\n",
    "\n",
    "- We will try two methods, one using DrQA and one using an autoregressive language model GPT2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
