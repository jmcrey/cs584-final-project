{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-29 20:05:07--  https://s3-eu-west-1.amazonaws.com/fever.public/wiki-pages.zip\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.102.11\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.102.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1713485474 (1.6G) [application/zip]\n",
      "Saving to: ‘/tmp/wiki-pages.zip’\n",
      "\n",
      "/tmp/wiki-pages.zip 100%[===================>]   1.60G  1.16MB/s    in 4m 19s  \n",
      "\n",
      "2021-04-29 20:09:27 (6.30 MB/s) - ‘/tmp/wiki-pages.zip’ saved [1713485474/1713485474]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-eu-west-1.amazonaws.com/fever.public/wiki-pages.zip -O /tmp/wiki-pages.zip\n",
    "!unzip -q /tmp/wiki-pages.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-29 20:13:53--  https://s3-eu-west-1.amazonaws.com/fever.public/train.jsonl\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.106.10\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.106.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33024303 (31M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘./data/train.jsonl’\n",
      "\n",
      "./data/train.jsonl  100%[===================>]  31.49M  17.3MB/s    in 1.8s    \n",
      "\n",
      "2021-04-29 20:13:55 (17.3 MB/s) - ‘./data/train.jsonl’ saved [33024303/33024303]\n",
      "\n",
      "--2021-04-29 20:13:55--  https://s3-eu-west-1.amazonaws.com/fever.public/shared_task_dev.jsonl\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.106.10\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.106.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4349935 (4.1M) [binary/octet-stream]\n",
      "Saving to: ‘./data/share_task_dev.jsonl’\n",
      "\n",
      "./data/share_task_d 100%[===================>]   4.15M  5.66MB/s    in 0.7s    \n",
      "\n",
      "2021-04-29 20:13:56 (5.66 MB/s) - ‘./data/share_task_dev.jsonl’ saved [4349935/4349935]\n",
      "\n",
      "--2021-04-29 20:13:56--  https://s3-eu-west-1.amazonaws.com/fever.public/shared_task_test.jsonl\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.106.10\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.106.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1599159 (1.5M) [binary/octet-stream]\n",
      "Saving to: ‘./data/share_task_test.jsonl’\n",
      "\n",
      "./data/share_task_t 100%[===================>]   1.52M  2.43MB/s    in 0.6s    \n",
      "\n",
      "2021-04-29 20:13:58 (2.43 MB/s) - ‘./data/share_task_test.jsonl’ saved [1599159/1599159]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-eu-west-1.amazonaws.com/fever.public/train.jsonl -O ./data/train.jsonl\n",
    "!wget https://s3-eu-west-1.amazonaws.com/fever.public/shared_task_dev.jsonl -O ./data/share_task_dev.jsonl\n",
    "!wget https://s3-eu-west-1.amazonaws.com/fever.public/shared_task_test.jsonl -O ./data/share_task_test.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Facebook Experiment\n",
    "\n",
    "1. Implement automatic masking\n",
    "2. Get the top 1 prediction from the LM \n",
    "3. Fill in the mask\n",
    "4. Use the claim and filled in sentence and input into an entailment model\n",
    "5. Input entailment into MLP for final fact-verification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import Iterable, List, Tuple\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    def __init__(self, tokenizer, model, predictor, mask_token: str = \"[MASK]\"):\n",
    "        self.nlp = spacy.load(\"en_core_web_trf\")\n",
    "        self.mask_token = mask_token\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.predictor = predictor\n",
    "    \n",
    "    def _mask(self, texts: List[str]) -> List[str]:\n",
    "        \"\"\" Masks the last named entity in the string \"\"\"\n",
    "        masked_sents = list()\n",
    "        for doc in self.nlp.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "            ents = doc.ents\n",
    "            target = ents[-1].text.split()[-1]\n",
    "            masked = doc.text.replace(target, mask_token)\n",
    "            masked_sents.append(masked)\n",
    "        return masked_sents\n",
    "    \n",
    "    def _fill_mask(self, texts: Iterable) -> List[str]:\n",
    "        \"\"\" Fills the masked token with the  top-1 predicted value \"\"\"\n",
    "        preds = list()\n",
    "        for text in texts:\n",
    "            tokens = self.tokenizer(text, return_tensors='tf')['input_ids']\n",
    "            masked_index = tf.where(tokens[0] == self.tokenizer.mask_token_id).numpy()\n",
    "\n",
    "            outputs = self.model(tokens)\n",
    "            logits = outputs.logits[0, masked_index.item(), :]\n",
    "            probs = tf.nn.softmax(logits)\n",
    "            topk = tf.math.top_k(probs, k=1)\n",
    "            values, predictions = topk.values.numpy(), topk.indices.numpy()\n",
    "            \n",
    "            pred = tokenizer.decode(predictions)\n",
    "            preds.append(text.replace(self.mask_token, pred))\n",
    "        return preds\n",
    "    \n",
    "    def forward(self, texts: List[str]) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Predicts the next word for the text \"\"\"\n",
    "        masked = self._mask(texts)\n",
    "        claims = self._fill_mask(masked)\n",
    "        labels = np.zeros(len(texts))\n",
    "        for indx, premise in enumerate(texts):\n",
    "            hyp = claims[indx]\n",
    "            entailment = self.predictor.predict(premise=premise, hypothesis=hyp)['label']\n",
    "            print(entailment)\n",
    "            if entailment == 'entailment':\n",
    "                label = 0\n",
    "            elif entailment == 'contradiction':\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            labels[indx] = label\n",
    "        return labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"Thomas Jefferson founded the University of Virginia after retiring.\"\n",
    "test2 = \"Microsoft's headquarters are in Redmond.\"\n",
    "test3 = \"Tim Roth is an English actor.\"\n",
    "texts = [test1,test2,test3]\n",
    "mask_token = \"[MASK]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-large-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForMaskedLM\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "model = TFBertForMaskedLM.from_pretrained('bert-large-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextualEntailmentPredictor' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6e83be478407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://storage.googleapis.com/allennlp-public-models/decomposable-attention-elmo-2020.04.09.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m predictor.forward(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpremise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Two women are wandering along the shore drinking iced tea.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhypothesis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Two women are sitting on a blanket near some rocks talking about politics.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextualEntailmentPredictor' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/decomposable-attention-elmo-2020.04.09.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entailment\n",
      "neutral\n",
      "contradiction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(tokenizer, model, predictor)\n",
    "pipe.forward(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import Iterable\n",
    "\n",
    "NLP = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "def mask_last_named_entity(texts: Iterable, mask_token: str = \"[MASK]\") -> str:\n",
    "    \"\"\" Masks the last named entity in the string \"\"\"\n",
    "    masked_sents = list()\n",
    "    for doc in NLP.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "        ents = doc.ents\n",
    "        target = ents[-1].text.split()[-1]\n",
    "        masked = doc.text.replace(target, mask_token)\n",
    "        masked_sents.append(masked)\n",
    "    return masked_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas Jefferson founded the University of [MASK] after retiring.',\n",
       " \"Microsoft's headquarters are in [MASK].\",\n",
       " 'Tim Roth is an [MASK] actor.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked = mask_last_named_entity([test1, test2, test3], mask_token) \n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tokenizer, model, sentences: list) -> list:\n",
    "    filled = list()\n",
    "    for sent in sentences:\n",
    "        tokens = tokenizer(sent, return_tensors='tf')['input_ids']\n",
    "        masked_index = tf.where(tokens[0] == tokenizer.mask_token_id).numpy()\n",
    "        \n",
    "        outputs = model(tokens)\n",
    "        logits = outputs.logits[0, masked_index.item(), :]\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        topk = tf.math.top_k(probs, k=1)\n",
    "        values, predictions = topk.values.numpy(), topk.indices.numpy()\n",
    "        \n",
    "        pred = tokenizer.decode(predictions)\n",
    "        filled.append(sent.replace('[MASK]', pred))\n",
    "    return filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas Jefferson founded the University of Virginia after retiring.',\n",
       " \"Microsoft's headquarters are in Atlanta.\",\n",
       " 'Tim Roth is an American actor.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(tokenizer, model, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_logits': [-3.349426507949829, 4.429577350616455, 0.9683250188827515],\n",
       " 'label_probs': [0.00040552925202064216,\n",
       "  0.9691717624664307,\n",
       "  0.030422717332839966],\n",
       " 'h2p_attention': [[0.6542736887931824,\n",
       "   0.04181644320487976,\n",
       "   0.04475216567516327,\n",
       "   0.047742560505867004,\n",
       "   0.03262277692556381,\n",
       "   0.02951790951192379,\n",
       "   0.022202881053090096,\n",
       "   0.02251291088759899,\n",
       "   0.02253689430654049,\n",
       "   0.033956028521060944,\n",
       "   0.02539297193288803,\n",
       "   0.02267284318804741],\n",
       "  [2.872008553822525e-05,\n",
       "   0.9997602105140686,\n",
       "   2.671237598406151e-05,\n",
       "   3.057234061998315e-05,\n",
       "   1.630776750971563e-05,\n",
       "   1.6658552340231836e-05,\n",
       "   2.244083043478895e-05,\n",
       "   1.6773410607129335e-05,\n",
       "   1.8311986423213966e-05,\n",
       "   3.357100285938941e-05,\n",
       "   1.4836954505881295e-05,\n",
       "   1.4931149053154513e-05],\n",
       "  [0.1017719954252243,\n",
       "   0.08759496361017227,\n",
       "   0.11182094365358353,\n",
       "   0.1164901927113533,\n",
       "   0.08897576481103897,\n",
       "   0.10866396129131317,\n",
       "   0.06278226524591446,\n",
       "   0.06688568741083145,\n",
       "   0.06301386654376984,\n",
       "   0.07898460328578949,\n",
       "   0.060093995183706284,\n",
       "   0.052921753376722336],\n",
       "  [0.0004623679560609162,\n",
       "   0.0005366414552554488,\n",
       "   0.0013094448950141668,\n",
       "   0.9844369292259216,\n",
       "   0.0037111323326826096,\n",
       "   0.0008001129608601332,\n",
       "   0.0007591390167362988,\n",
       "   0.0039961375296115875,\n",
       "   0.0005880563985556364,\n",
       "   0.002271205186843872,\n",
       "   0.0006370912888087332,\n",
       "   0.0004917888436466455],\n",
       "  [0.02187896892428398,\n",
       "   0.016263578087091446,\n",
       "   0.043618641793727875,\n",
       "   0.3232429027557373,\n",
       "   0.12519384920597076,\n",
       "   0.21581538021564484,\n",
       "   0.03572533279657364,\n",
       "   0.09783703833818436,\n",
       "   0.0363800972700119,\n",
       "   0.04659579321742058,\n",
       "   0.022637616842985153,\n",
       "   0.014810697175562382],\n",
       "  [0.01724625565111637,\n",
       "   0.011928700841963291,\n",
       "   0.031436171382665634,\n",
       "   0.23784267902374268,\n",
       "   0.06237536668777466,\n",
       "   0.4272248446941376,\n",
       "   0.03883986175060272,\n",
       "   0.05050591006875038,\n",
       "   0.05539629980921745,\n",
       "   0.04054819792509079,\n",
       "   0.016226349398493767,\n",
       "   0.010429393500089645],\n",
       "  [0.01023787073791027,\n",
       "   0.010661045089364052,\n",
       "   0.012147895060479641,\n",
       "   0.4098244607448578,\n",
       "   0.0244853924959898,\n",
       "   0.04978817701339722,\n",
       "   0.3647692799568176,\n",
       "   0.02813608944416046,\n",
       "   0.031522661447525024,\n",
       "   0.04330052062869072,\n",
       "   0.008045821450650692,\n",
       "   0.0070806886069476604],\n",
       "  [0.012574701569974422,\n",
       "   0.01323822420090437,\n",
       "   0.03239866718649864,\n",
       "   0.24182693660259247,\n",
       "   0.13379545509815216,\n",
       "   0.3817496597766876,\n",
       "   0.06834885478019714,\n",
       "   0.05440392345190048,\n",
       "   0.015210311859846115,\n",
       "   0.025607023388147354,\n",
       "   0.01224629208445549,\n",
       "   0.008599936962127686],\n",
       "  [0.025505196303129196,\n",
       "   0.021940959617495537,\n",
       "   0.04952190816402435,\n",
       "   0.0795852392911911,\n",
       "   0.06907019764184952,\n",
       "   0.5571256279945374,\n",
       "   0.056920699775218964,\n",
       "   0.0375341959297657,\n",
       "   0.03062898851931095,\n",
       "   0.041156213730573654,\n",
       "   0.017572682350873947,\n",
       "   0.013438118621706963],\n",
       "  [0.00329997343942523,\n",
       "   0.003710755379870534,\n",
       "   0.004895895253866911,\n",
       "   0.012878671288490295,\n",
       "   0.009935972280800343,\n",
       "   0.05006616190075874,\n",
       "   0.6458715796470642,\n",
       "   0.012672973796725273,\n",
       "   0.16958396136760712,\n",
       "   0.08052671700716019,\n",
       "   0.003340700874105096,\n",
       "   0.0032165832817554474],\n",
       "  [0.011912988498806953,\n",
       "   0.009290074929594994,\n",
       "   0.01999199204146862,\n",
       "   0.4228837490081787,\n",
       "   0.02823156863451004,\n",
       "   0.020830148831009865,\n",
       "   0.014663194306194782,\n",
       "   0.3370856046676636,\n",
       "   0.05857554078102112,\n",
       "   0.05190882086753845,\n",
       "   0.01714303158223629,\n",
       "   0.007483314722776413],\n",
       "  [0.02818572334945202,\n",
       "   0.02577592246234417,\n",
       "   0.05009709298610687,\n",
       "   0.4053546190261841,\n",
       "   0.0797458291053772,\n",
       "   0.07759219408035278,\n",
       "   0.027934938669204712,\n",
       "   0.16949701309204102,\n",
       "   0.049019668251276016,\n",
       "   0.05364980176091194,\n",
       "   0.021943219006061554,\n",
       "   0.011204016394913197],\n",
       "  [0.0037910158280283213,\n",
       "   0.003787602763622999,\n",
       "   0.005147991701960564,\n",
       "   0.04601551592350006,\n",
       "   0.00764108682051301,\n",
       "   0.009489473886787891,\n",
       "   0.012797742150723934,\n",
       "   0.11391094326972961,\n",
       "   0.20984463393688202,\n",
       "   0.5805692076683044,\n",
       "   0.003896513720974326,\n",
       "   0.0031084076035767794],\n",
       "  [0.07601429522037506,\n",
       "   0.0672522634267807,\n",
       "   0.08519986271858215,\n",
       "   0.13195310533046722,\n",
       "   0.07711159437894821,\n",
       "   0.08093579858541489,\n",
       "   0.07062586396932602,\n",
       "   0.09599754959344864,\n",
       "   0.08104497194290161,\n",
       "   0.07409653812646866,\n",
       "   0.0908690020442009,\n",
       "   0.06889912486076355],\n",
       "  [0.08347289264202118,\n",
       "   0.08220743387937546,\n",
       "   0.08219706267118454,\n",
       "   0.08517543971538544,\n",
       "   0.0796607956290245,\n",
       "   0.08381453901529312,\n",
       "   0.08455304801464081,\n",
       "   0.08125217258930206,\n",
       "   0.08679299056529999,\n",
       "   0.08751248568296432,\n",
       "   0.08170203119516373,\n",
       "   0.08165904879570007]],\n",
       " 'p2h_attention': [[0.5794918537139893,\n",
       "   0.03807639330625534,\n",
       "   0.03711562231183052,\n",
       "   0.018810685724020004,\n",
       "   0.028771674260497093,\n",
       "   0.03250572457909584,\n",
       "   0.027426959946751595,\n",
       "   0.02817908674478531,\n",
       "   0.037509508430957794,\n",
       "   0.020980430766940117,\n",
       "   0.0346122644841671,\n",
       "   0.05088246986269951,\n",
       "   0.02403539977967739,\n",
       "   0.021610762923955917,\n",
       "   0.019991042092442513],\n",
       "  [2.7934614990954287e-05,\n",
       "   0.9997095465660095,\n",
       "   2.409435182926245e-05,\n",
       "   1.6466796296299435e-05,\n",
       "   1.6131029042298906e-05,\n",
       "   1.6957666957750916e-05,\n",
       "   2.1541489331866615e-05,\n",
       "   2.2375201297109015e-05,\n",
       "   2.433750887576025e-05,\n",
       "   1.779402191459667e-05,\n",
       "   2.0358053006930277e-05,\n",
       "   3.5096280043944716e-05,\n",
       "   1.8112077668774873e-05,\n",
       "   1.4420802472159266e-05,\n",
       "   1.4849394574412145e-05],\n",
       "  [0.05505998060107231,\n",
       "   0.04919452220201492,\n",
       "   0.056648142635822296,\n",
       "   0.07400111854076385,\n",
       "   0.07967913150787354,\n",
       "   0.08230549842119217,\n",
       "   0.04520675167441368,\n",
       "   0.10085338354110718,\n",
       "   0.10116823762655258,\n",
       "   0.04323844611644745,\n",
       "   0.08068622648715973,\n",
       "   0.12562775611877441,\n",
       "   0.045338574796915054,\n",
       "   0.033647116273641586,\n",
       "   0.02734515443444252],\n",
       "  [0.0009355717920698225,\n",
       "   0.0008967726025730371,\n",
       "   0.0009399427799507976,\n",
       "   0.8861116170883179,\n",
       "   0.009404830634593964,\n",
       "   0.009918330237269402,\n",
       "   0.024291234090924263,\n",
       "   0.01198995765298605,\n",
       "   0.002589577343314886,\n",
       "   0.0018115841085091233,\n",
       "   0.027184026315808296,\n",
       "   0.016190404072403908,\n",
       "   0.006454814691096544,\n",
       "   0.0008299998589791358,\n",
       "   0.0004513235471677035],\n",
       "  [0.021218357607722282,\n",
       "   0.015876971185207367,\n",
       "   0.02382885478436947,\n",
       "   0.11087314039468765,\n",
       "   0.12089945375919342,\n",
       "   0.08633386343717575,\n",
       "   0.048170171678066254,\n",
       "   0.22017784416675568,\n",
       "   0.07459443062543869,\n",
       "   0.046389225870370865,\n",
       "   0.06023476645350456,\n",
       "   0.10571824759244919,\n",
       "   0.0355757400393486,\n",
       "   0.016098948195576668,\n",
       "   0.014009983278810978],\n",
       "  [0.007182839326560497,\n",
       "   0.0060677845031023026,\n",
       "   0.010887712240219116,\n",
       "   0.008943160064518452,\n",
       "   0.07797285914421082,\n",
       "   0.22123010456562042,\n",
       "   0.03664519265294075,\n",
       "   0.23503394424915314,\n",
       "   0.22510674595832825,\n",
       "   0.08745221793651581,\n",
       "   0.016627395525574684,\n",
       "   0.038483958691358566,\n",
       "   0.016529537737369537,\n",
       "   0.006321761757135391,\n",
       "   0.005514828953891993],\n",
       "  [0.0034151198342442513,\n",
       "   0.005166756454855204,\n",
       "   0.003976254723966122,\n",
       "   0.005363484378904104,\n",
       "   0.008158748969435692,\n",
       "   0.012713098898530006,\n",
       "   0.16970519721508026,\n",
       "   0.026599247008562088,\n",
       "   0.014537567272782326,\n",
       "   0.7131137251853943,\n",
       "   0.007398549467325211,\n",
       "   0.008757811039686203,\n",
       "   0.014090878888964653,\n",
       "   0.003486963687464595,\n",
       "   0.0035166407469660044],\n",
       "  [0.007020092569291592,\n",
       "   0.007829156704246998,\n",
       "   0.008587857708334923,\n",
       "   0.057237494736909866,\n",
       "   0.04529653117060661,\n",
       "   0.033514320850372314,\n",
       "   0.026537198573350906,\n",
       "   0.04292226955294609,\n",
       "   0.019434040412306786,\n",
       "   0.028366493061184883,\n",
       "   0.3448042869567871,\n",
       "   0.10772694647312164,\n",
       "   0.25426384806632996,\n",
       "   0.009608558379113674,\n",
       "   0.006850909907370806],\n",
       "  [0.0064016710966825485,\n",
       "   0.007786046247929335,\n",
       "   0.0073701441287994385,\n",
       "   0.007672684732824564,\n",
       "   0.015343120321631432,\n",
       "   0.033485546708106995,\n",
       "   0.02708335593342781,\n",
       "   0.010931476950645447,\n",
       "   0.014446306973695755,\n",
       "   0.3457801043987274,\n",
       "   0.054580431431531906,\n",
       "   0.028380559757351875,\n",
       "   0.42668288946151733,\n",
       "   0.007389456499367952,\n",
       "   0.006666319444775581],\n",
       "  [0.005955519154667854,\n",
       "   0.008813525550067425,\n",
       "   0.005704083014279604,\n",
       "   0.0182973463088274,\n",
       "   0.01213388703763485,\n",
       "   0.015133924782276154,\n",
       "   0.02297080121934414,\n",
       "   0.01136326789855957,\n",
       "   0.011985691264271736,\n",
       "   0.10138151049613953,\n",
       "   0.029865190386772156,\n",
       "   0.019178833812475204,\n",
       "   0.7288947105407715,\n",
       "   0.00417145574465394,\n",
       "   0.004150256048887968],\n",
       "  [0.05540170893073082,\n",
       "   0.048454806208610535,\n",
       "   0.05398600921034813,\n",
       "   0.06384696811437607,\n",
       "   0.07333154231309891,\n",
       "   0.07533687353134155,\n",
       "   0.05309580639004707,\n",
       "   0.06760138273239136,\n",
       "   0.06366085261106491,\n",
       "   0.05231945589184761,\n",
       "   0.12269264459609985,\n",
       "   0.09758006036281586,\n",
       "   0.060854651033878326,\n",
       "   0.0636373907327652,\n",
       "   0.04819972440600395],\n",
       "  [0.06747937947511673,\n",
       "   0.06651818752288818,\n",
       "   0.0648544505238533,\n",
       "   0.06723150610923767,\n",
       "   0.06544718891382217,\n",
       "   0.0660543292760849,\n",
       "   0.06374125927686691,\n",
       "   0.06475922465324402,\n",
       "   0.06640920788049698,\n",
       "   0.06871884316205978,\n",
       "   0.07306010276079178,\n",
       "   0.06796570867300034,\n",
       "   0.06622332334518433,\n",
       "   0.06582118570804596,\n",
       "   0.06571605056524277]],\n",
       " 'premise_tokens': ['Two',\n",
       "  'women',\n",
       "  'are',\n",
       "  'wandering',\n",
       "  'along',\n",
       "  'the',\n",
       "  'shore',\n",
       "  'drinking',\n",
       "  'iced',\n",
       "  'tea',\n",
       "  '.',\n",
       "  '@@NULL@@'],\n",
       " 'hypothesis_tokens': ['Two',\n",
       "  'women',\n",
       "  'are',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'a',\n",
       "  'blanket',\n",
       "  'near',\n",
       "  'some',\n",
       "  'rocks',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'politics',\n",
       "  '.',\n",
       "  '@@NULL@@'],\n",
       " 'label': 'contradiction'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = predictor.predict(\n",
    "    premise=\"Two women are wandering along the shore drinking iced tea.\",\n",
    "    hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\"\n",
    ")\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAMA Probe into BART\n",
    "\n",
    "The goal of this section is to understand the amount of knowledge stored in BART using the [LAMA probe](https://github.com/facebookresearch/LAMA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From BERT to BART\n",
    "\n",
    "Insert the BART model in lieu of BERT to see if performance increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting a Context Layer into the Pipeline\n",
    "\n",
    "- We will try two methods, one using DrQA and one using an autoregressive language model GPT2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
